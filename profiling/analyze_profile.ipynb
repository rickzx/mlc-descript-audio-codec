{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook analyzes the .csv file generated by TVM VM profiler.\n",
    "\n",
    "To profile a TVM VM\n",
    "\n",
    "```\n",
    "report = vm.profile(\"encode\", audio_data, *effects, *const_params_dict[\"encode\"])\n",
    "csv = report.csv()\n",
    "\n",
    "with open(\"profile_stream.csv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(csv)\n",
    "    print(\"Profile saved to profile_stream.csv\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time (ms): 43.627\n",
      "Top K Time-Consuming Operators:\n",
      "                                   Name                                                                       Argument Shapes  Duration (ms)\n",
      "           vm.builtin.check_tensor_info                                                                    float32[1, 1, 512]       0.875334\n",
      "                  fused_conv1d38_add301 float32[1, 512, 16], float32[1024, 512, 16], float32[1, 1024, 1], float32[1, 1024, 1]       0.460000\n",
      "                                   topk                                                         float32[1, 1024], int32[1, 1]       0.387792\n",
      "    vm.builtin.cached_padding_1d_update                                                                   float32[1, 64, 512]       0.373417\n",
      "      fused_reshape16_snake2_reshape161                          float32[1, 256, 64], float32[1, 256, 1], float32[1, 256, 64]       0.364334\n",
      "    vm.builtin.cached_padding_1d_update                                                                   float32[1, 256, 64]       0.352542\n",
      "                  fused_conv1d41_add301       float32[1, 8, 1], float32[1024, 8, 1], float32[1, 1024, 1], float32[1, 1024, 1]       0.350792\n",
      "    vm.builtin.cached_padding_1d_update                                                                   float32[1, 64, 512]       0.348833\n",
      "                                   topk                                                         float32[1, 1024], int32[1, 1]       0.342375\n",
      "                  fused_conv1d41_add301       float32[1, 8, 1], float32[1024, 8, 1], float32[1, 1024, 1], float32[1, 1024, 1]       0.339000\n",
      "    vm.builtin.cached_padding_1d_update                                                                    float32[1, 512, 8]       0.335750\n",
      "    vm.builtin.cached_padding_1d_update                                                                  float32[1, 128, 256]       0.334375\n",
      "    vm.builtin.cached_padding_1d_update                                                                   float32[1, 64, 512]       0.333542\n",
      "    vm.builtin.cached_padding_1d_update                                                                    float32[1, 512, 8]       0.330041\n",
      "    vm.builtin.cached_padding_1d_update                                                                    float32[1, 512, 8]       0.327458\n",
      "    vm.builtin.cached_padding_1d_update                                                                  float32[1, 128, 256]       0.326583\n",
      "    vm.builtin.cached_padding_1d_update                                                                  float32[1, 128, 256]       0.325041\n",
      "                                   topk                                                         float32[1, 1024], int32[1, 1]       0.320709\n",
      "                                   topk                                                         float32[1, 1024], int32[1, 1]       0.316917\n",
      "                                   topk                                                         float32[1, 1024], int32[1, 1]       0.312083\n",
      "    vm.builtin.cached_padding_1d_update                                                                   float32[1, 256, 64]       0.310542\n",
      "                                   topk                                                         float32[1, 1024], int32[1, 1]       0.310209\n",
      "                                   topk                                                         float32[1, 1024], int32[1, 1]       0.303125\n",
      "                  fused_conv1d39_add301 float32[1, 1024, 3], float32[1024, 1024, 3], float32[1, 1024, 1], float32[1, 1024, 1]       0.302833\n",
      "    vm.builtin.cached_padding_1d_update                                                                    float32[1, 512, 8]       0.299500\n",
      "                                   topk                                                         float32[1, 1024], int32[1, 1]       0.292000\n",
      "    vm.builtin.cached_padding_1d_update                                                                   float32[1, 64, 512]       0.291708\n",
      "    vm.builtin.cached_padding_1d_update                                                                   float32[1, 256, 64]       0.286167\n",
      "    vm.builtin.cached_padding_1d_update                                                                   float32[1, 256, 64]       0.279208\n",
      "    vm.builtin.cached_padding_1d_update                                                                  float32[1, 128, 256]       0.272833\n",
      "    vm.builtin.cached_padding_1d_update                                                                   float32[1, 64, 512]       0.262667\n",
      "                                   topk                                                         float32[1, 1024], int32[1, 1]       0.259125\n",
      "                  fused_conv1d31_add241    float32[1, 256, 82], float32[256, 256, 7], float32[1, 256, 1], float32[1, 256, 64]       0.255875\n",
      "    vm.builtin.cached_padding_1d_update                                                                   float32[1, 64, 512]       0.252042\n",
      "    vm.builtin.cached_padding_1d_update                                                                   float32[1, 256, 64]       0.251875\n",
      "                  fused_conv1d32_add241   float32[1, 256, 118], float32[256, 256, 7], float32[1, 256, 1], float32[1, 256, 64]       0.251334\n",
      "    vm.builtin.cached_padding_1d_update                                                                    float32[1, 512, 8]       0.246375\n",
      "    vm.builtin.cached_padding_1d_update                                                                   float32[1, 64, 512]       0.244708\n",
      "                  fused_conv1d40_add311          float32[1, 1024, 1], float32[8, 1024, 1], float32[1, 8, 1], float32[1, 8, 1]       0.243959\n",
      "    vm.builtin.cached_padding_1d_update                                                                   float32[1, 64, 512]       0.242416\n",
      "                  fused_conv1d37_add271     float32[1, 512, 62], float32[512, 512, 7], float32[1, 512, 1], float32[1, 512, 8]       0.240792\n",
      "                  fused_conv1d33_add271    float32[1, 256, 72], float32[512, 256, 16], float32[1, 512, 1], float32[1, 512, 8]       0.240334\n",
      "                  fused_conv1d40_add311          float32[1, 1024, 1], float32[8, 1024, 1], float32[1, 8, 1], float32[1, 8, 1]       0.240084\n",
      "                             subtract11                         float32[1, 1024, 1], float32[1, 1024, 1], float32[1, 1024, 1]       0.239042\n",
      "    vm.builtin.cached_padding_1d_update                                                                  float32[1, 128, 256]       0.238417\n",
      "    vm.builtin.cached_padding_1d_update                                                                    float32[1, 512, 8]       0.236250\n",
      "fused_matmul_multiply29_subtract_add321    float32[1, 8], float32[8, 1024], float32[1, 1], float32[1, 1024], float32[1, 1024]       0.236000\n",
      "                  fused_conv1d40_add311          float32[1, 1024, 1], float32[8, 1024, 1], float32[1, 8, 1], float32[1, 8, 1]       0.235000\n",
      "    vm.builtin.cached_padding_1d_update                                                                   float32[1, 256, 64]       0.230125\n",
      "                  fused_conv1d24_add211  float32[1, 128, 262], float32[128, 128, 7], float32[1, 128, 1], float32[1, 128, 256]       0.230083\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"profile_stream.csv\")\n",
    "\n",
    "df[\"Duration (ms)\"] = df[\"Duration (us)\"] / 1000\n",
    "total_time_ms = df[\"Duration (ms)\"].sum()\n",
    "\n",
    "K = 50\n",
    "\n",
    "# Get the top K time-consuming operators\n",
    "top_k_operators = df.nlargest(K, \"Duration (ms)\")[[\"Name\", \"Argument Shapes\", \"Duration (ms)\"]]\n",
    "\n",
    "# Get only the top K operators with conv1d in it\n",
    "# top_k_operators = top_k_operators[top_k_operators[\"Name\"].str.contains(\"conv1d\")]\n",
    "\n",
    "print(f\"Total Time (ms): {total_time_ms:.3f}\")\n",
    "print(\"Top K Time-Consuming Operators:\")\n",
    "print(top_k_operators.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlc-audio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
