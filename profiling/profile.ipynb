{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cfruan/miniconda3/envs/mlc-audio/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x11cb64510>\n",
      "conv1d(data)\n",
      "setup: from __main__ import conv1d, data\n",
      "  4.81 ms\n",
      "  1 measurement, 1000 runs , 16 threads\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.nn.utils import weight_norm\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "import timeit\n",
    "\n",
    "N = 1\n",
    "iH = 220500\n",
    "C = 128\n",
    "wH = 7\n",
    "\n",
    "\n",
    "def WNConv1d(*args, **kwargs):\n",
    "    return weight_norm(nn.Conv1d(*args, **kwargs))\n",
    "\n",
    "\n",
    "conv1d = WNConv1d(C, C, wH, dilation=1, padding=3).to('mps')\n",
    "\n",
    "# torch.manual_seed(0)\n",
    "a_np = np.random.uniform(0, 0.5, (N, iH, C)).astype(\"float32\")\n",
    "data = torch.from_numpy(a_np.transpose((0, 2, 1))).to(\"mps\")\n",
    "\n",
    "# with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "#     with record_function(\"model_inference\"):\n",
    "#         out = conv1d(data)\n",
    "\n",
    "# print(out)\n",
    "\n",
    "# print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
    "# print(\"\\n\\n\")\n",
    "# print(prof.key_averages(group_by_input_shape=True).table(sort_by=\"cpu_time_total\", row_limit=10))\n",
    "\n",
    "import torch.utils.benchmark as benchmark\n",
    "\n",
    "# Create a timer for the Conv1D operation\n",
    "t = benchmark.Timer(\n",
    "    stmt=\"conv1d(data)\",\n",
    "    setup=\"from __main__ import conv1d, data\",\n",
    "    num_threads=torch.get_num_threads(),\n",
    "    globals={\"conv1d\": conv1d, \"data\": data},\n",
    ")\n",
    "\n",
    "# Run the benchmark\n",
    "result = t.timeit(1000)\n",
    "print(result)\n",
    "\n",
    "\n",
    "# # time\n",
    "# execution_time = timeit.timeit(lambda: conv1d(data), number=1000)\n",
    "\n",
    "# print(f\"Average execution time: {execution_time / 1000:.6f} seconds per call\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:04:20] /Users/cfruan/Documents/tvm-unity/src/target/llvm/llvm_instance.cc:226: Error: Using LLVM 19.1.1 with `-mcpu=apple-latest` is not valid in `-mtriple=arm64-apple-macos`, using default `-mcpu=generic`\n",
      "[23:04:20] /Users/cfruan/Documents/tvm-unity/src/target/llvm/llvm_instance.cc:226: Error: Using LLVM 19.1.1 with `-mcpu=apple-latest` is not valid in `-mtriple=arm64-apple-macos`, using default `-mcpu=generic`\n",
      "[23:04:20] /Users/cfruan/Documents/tvm-unity/src/target/llvm/llvm_instance.cc:226: Error: Using LLVM 19.1.1 with `-mcpu=apple-latest` is not valid in `-mtriple=arm64-apple-macos`, using default `-mcpu=generic`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time summary:\n",
      " mean (ms)   median (ms)    max (ms)     min (ms)     std (ms)  \n",
      "   0.7746       0.7521       0.8622       0.7485       0.0439                  \n",
      "Name                                 Duration (us)  Percent  Device  Count                                                                     Argument Shapes  \n",
      "vm.builtin.check_tensor_info               1875.12    43.98  metal0      1                                                                 float32[1, 512, 62]  \n",
      "fused_conv1d_add                           1040.79    24.41  metal0      1   float32[1, 512, 62], float32[512, 512, 7], float32[1, 512, 1], float32[1, 512, 8]  \n",
      "fused_tir_square_sum                        299.46     7.02  metal0      1                                            float32[512, 512, 7], float32[512, 1, 1]  \n",
      "fused_tir_sqrt_divide_multiply              271.75     6.37  metal0      1  float32[512, 1, 1], float32[512, 512, 7], float32[512, 1, 1], float32[512, 512, 7]  \n",
      "vm.builtin.cached_padding_1d_update         250.62     5.88  metal0      2                                                                 float32[1, 512, 62]  \n",
      "vm.builtin.make_tuple                       148.38     3.48  metal0      1                                                                  float32[1, 512, 8]  \n",
      "vm.builtin.match_shape                       97.29     2.28  metal0      1                                                                 float32[1, 512, 62]  \n",
      "vm.builtin.reshape                           70.50     1.65  metal0      1                                                                        float32[512]  \n",
      "----------                                                                                                                                                      \n",
      "Sum                                        4053.92    95.08              9                                                                                      \n",
      "Total                                      4143.12             cpu0      1                                                                                      \n",
      "Total                                      4263.67           metal0      1                                                                                      \n",
      "\n",
      "Configuration\n",
      "-------------\n",
      "Number of threads: 24\n",
      "Executor: VM\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tvm\n",
    "\n",
    "from tvm import relax\n",
    "from tvm.relax.frontend import nn\n",
    "\n",
    "from typing import Optional\n",
    "from tvm import te\n",
    "from tvm import dlight as dl\n",
    "from tvm.target import Target\n",
    "import numpy as np\n",
    "import tempfile\n",
    "\n",
    "import timeit\n",
    "\n",
    "from mlc_dac.layers import CachedWNConv1d\n",
    "\n",
    "conv1d = CachedWNConv1d(512, 512, 7, stride=1, dilation=9, padding=0)\n",
    "mod, params = conv1d.export_tvm(\n",
    "    {\"forward\": {\"x\": nn.spec.Tensor((1, 512, 62), \"float32\")}},\n",
    "    debug=True\n",
    ")\n",
    "\n",
    "target = Target.from_device(\"metal\")\n",
    "seq = tvm.transform.Sequential(\n",
    "    [\n",
    "        tvm.relax.transform.LegalizeOps(),\n",
    "        tvm.relax.transform.AnnotateTIROpPattern(),\n",
    "        tvm.relax.transform.FoldConstant(),\n",
    "        tvm.relax.transform.FuseOps(),\n",
    "        tvm.relax.transform.FuseTIR(),\n",
    "        dl.ApplyDefaultSchedule(\n",
    "            dl.gpu.Matmul(),\n",
    "            dl.gpu.GEMV(),\n",
    "            dl.gpu.Reduction(),\n",
    "            dl.gpu.GeneralReduction(),\n",
    "            dl.gpu.Fallback(),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "with target:\n",
    "    mod = seq(mod)\n",
    "\n",
    "device = tvm.metal()\n",
    "ex = relax.build(mod, target)\n",
    "vm = relax.VirtualMachine(ex, device, profile=True)\n",
    "effects = vm.module[\"_initialize_effect\"]()\n",
    "\n",
    "params = [np.random.randn(*param.shape).astype(\"float32\") for _, param in params]\n",
    "params = [tvm.nd.array(param, device=device) for param in params]\n",
    "\n",
    "np.random.seed(0)\n",
    "audio_data = np.random.randn(1, 512, 62).astype(\"float32\")\n",
    "audio_data = tvm.nd.array(audio_data, device=device)\n",
    "\n",
    "time_eval = vm.time_evaluator(\"forward\", device, 10, 5)(audio_data, *effects, *params)\n",
    "print(time_eval)\n",
    "\n",
    "report = vm.profile(\"forward\", audio_data, *effects, *params)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "\n",
    "from tvm import relax\n",
    "from tvm.relax.frontend import nn\n",
    "\n",
    "from typing import Optional\n",
    "from tvm import te\n",
    "from tvm import dlight as dl\n",
    "from tvm.target import Target\n",
    "import numpy as np\n",
    "import tempfile\n",
    "\n",
    "import timeit\n",
    "\n",
    "from mlc_dac.layers import CachedWNConv1d\n",
    "\n",
    "conv1d = CachedWNConv1d(512, 512, 7, stride=1, dilation=9, padding=0)\n",
    "mod, params = conv1d.export_tvm(\n",
    "    {\"forward\": {\"x\": nn.spec.Tensor((1, 512, 62), \"float32\")}},\n",
    "    debug=True\n",
    ")\n",
    "\n",
    "trials = 5000\n",
    "target = Target.from_device(\"metal\")\n",
    "\n",
    "with target, tempfile.TemporaryDirectory() as tmp_dir:\n",
    "    seq = tvm.transform.Sequential(\n",
    "        [\n",
    "            relax.get_pipeline(\"zero\"),\n",
    "            relax.transform.MetaScheduleTuneTIR(work_dir=tmp_dir, max_trials_global=trials),\n",
    "            relax.transform.MetaScheduleApplyDatabase(work_dir=tmp_dir),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    mod = seq(mod)\n",
    "\n",
    "mod.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = tvm.metal()\n",
    "with target:\n",
    "    seq = dl.ApplyDefaultSchedule(\n",
    "        dl.gpu.Fallback(),\n",
    "    )\n",
    "    vm_mod = seq(mod)\n",
    "\n",
    "# vm_mod.show()\n",
    "ex = relax.build(vm_mod, target)\n",
    "vm = relax.VirtualMachine(ex, device, profile=True)\n",
    "effects = vm.module[\"_initialize_effect\"]()\n",
    "\n",
    "tvm_params = [np.random.randn(*param.shape).astype(\"float32\") for _, param in params]\n",
    "tvm_params = [tvm.nd.array(param, device=device) for param in tvm_params]\n",
    "\n",
    "np.random.seed(0)\n",
    "audio_data = np.random.randn(1, 512, 62).astype(\"float32\")\n",
    "audio_data = tvm.nd.array(audio_data, device=device)\n",
    "\n",
    "time_eval = vm.time_evaluator(\"forward\", device, 10, 5)(audio_data, *effects, *tvm_params)\n",
    "print(time_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "\n",
    "from tvm import relax\n",
    "from tvm.relax.frontend import nn\n",
    "\n",
    "from typing import Optional\n",
    "from tvm import te\n",
    "from tvm import dlight as dl\n",
    "from tvm.target import Target\n",
    "import numpy as np\n",
    "import tempfile\n",
    "\n",
    "from mlc_dac.layers import WNConv1d\n",
    "\n",
    "conv1d = nn.Conv1D(128, 128, 7, dilation=1, padding=3)\n",
    "mod, params = conv1d.export_tvm(\n",
    "    {\"forward\": {\"x\": nn.spec.Tensor((1, 128, \"seq_len\"), \"float32\")}}\n",
    ")\n",
    "\n",
    "trials = 2000\n",
    "target = Target.from_device(\"metal\")\n",
    "\n",
    "with target, tempfile.TemporaryDirectory() as tmp_dir:\n",
    "    seq = tvm.transform.Sequential(\n",
    "        [\n",
    "            relax.get_pipeline(\"zero\"),\n",
    "            relax.transform.MetaScheduleTuneTIR(work_dir=tmp_dir, max_trials_global=trials),\n",
    "            relax.transform.MetaScheduleApplyDatabase(work_dir=tmp_dir),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    mod = seq(mod)\n",
    "\n",
    "mod.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile saved to profile_conv1d.csv\n"
     ]
    }
   ],
   "source": [
    "ex = relax.build(mod, target)\n",
    "device = tvm.metal()\n",
    "\n",
    "np.random.seed(0)\n",
    "vm = relax.VirtualMachine(ex, device, profile=True)\n",
    "tvm_data = tvm.nd.array(data.cpu(), device=device)\n",
    "tvm_params = [np.random.randn(*param.shape).astype(\"float32\") for _, param in params]\n",
    "tvm_params = [tvm.nd.array(param, device=device) for param in tvm_params]\n",
    "\n",
    "# output_tvm = vm[\"forward\"](tvm_data, *tvm_params)\n",
    "# output_tvm = output_tvm.asnumpy()\n",
    "\n",
    "# output_tvm\n",
    "\n",
    "report = vm.profile(\"forward\", tvm_data, *tvm_params)\n",
    "csv = report.csv()\n",
    "\n",
    "with open(\"profile_conv1d.csv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(csv)\n",
    "    print(\"Profile saved to profile_conv1d.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time summary:\n",
      " mean (ms)   median (ms)    max (ms)     min (ms)     std (ms)  \n",
      "   6.4725       6.4723       6.5175       6.4398       0.0245                  \n"
     ]
    }
   ],
   "source": [
    "vm_eval = relax.VirtualMachine(ex, device)\n",
    "timing_res = vm_eval.time_evaluator(\"forward\", device, number=3, repeat=10, min_repeat_ms=100)(tvm_data, *tvm_params)\n",
    "print(timing_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time summary:\n",
      " mean (ms)   median (ms)    max (ms)     min (ms)     std (ms)  \n",
      "  25.6094      25.5991      26.0009      25.1240       0.3021                  \n"
     ]
    }
   ],
   "source": [
    "import tvm\n",
    "\n",
    "from tvm import relax\n",
    "from tvm.relax.frontend import nn\n",
    "\n",
    "from typing import Optional\n",
    "from tvm import te\n",
    "from tvm import dlight as dl\n",
    "from tvm.target import Target\n",
    "import numpy as np\n",
    "import tempfile\n",
    "\n",
    "from mlc_dac.layers import WNConv1d\n",
    "\n",
    "# conv1d = WNConv1d(128, 128, 7, dilation=1, padding=3)\n",
    "\n",
    "conv1d = nn.Conv1D(128, 128, 7, dilation=1, padding=3)\n",
    "mod, params = conv1d.export_tvm(\n",
    "    {\"forward\": {\"x\": nn.spec.Tensor((2, 128, 220500), \"float32\")}}\n",
    ")\n",
    "\n",
    "trials = 2000\n",
    "target = Target.from_device(\"metal\")\n",
    "\n",
    "with target:\n",
    "    seq = tvm.transform.Sequential(\n",
    "        [\n",
    "            relax.get_pipeline(\"zero\"),\n",
    "            dl.ApplyDefaultSchedule(\n",
    "                dl.gpu.Matmul(),\n",
    "                dl.gpu.GEMV(),\n",
    "                dl.gpu.Reduction(),\n",
    "                dl.gpu.GeneralReduction(),\n",
    "                dl.gpu.Fallback(),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    mod2 = seq(mod)\n",
    "\n",
    "ex2 = relax.build(mod2, target)\n",
    "device = tvm.metal()\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "N = 2\n",
    "H = 220500\n",
    "C = 128\n",
    "\n",
    "data = np.random.uniform(0, 0.5, (N, C, H)).astype(\"float32\")\n",
    "tvm_data = tvm.nd.array(data, device=device)\n",
    "tvm_params = [np.random.randn(*param.shape).astype(\"float32\") for _, param in params]\n",
    "tvm_params = [tvm.nd.array(param, device=device) for param in tvm_params]\n",
    "\n",
    "# output_tvm = vm[\"forward\"](tvm_data, *tvm_params)\n",
    "# output_tvm = output_tvm.asnumpy()\n",
    "\n",
    "# output_tvm\n",
    "\n",
    "vm_eval_2 = relax.VirtualMachine(ex2, device)\n",
    "timing_res = vm_eval_2.time_evaluator(\"forward\", device, number=10, repeat=10, min_repeat_ms=100)(tvm_data, *tvm_params)\n",
    "print(timing_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "\n",
    "from tvm import relax\n",
    "from tvm.relax.frontend import nn\n",
    "\n",
    "from typing import Optional\n",
    "from tvm import te\n",
    "from tvm import dlight as dl\n",
    "from tvm.target import Target\n",
    "import numpy as np\n",
    "import tempfile\n",
    "\n",
    "import timeit\n",
    "\n",
    "from mlc_dac.layers import CachedWNConv1d\n",
    "\n",
    "conv1d = nn.Conv1D(512, 512, 7, stride=1, dilation=3, padding=0)\n",
    "mod, params = conv1d.export_tvm(\n",
    "    {\"forward\": {\"x\": nn.spec.Tensor((1, 512, 62), \"float32\")}},\n",
    "    debug=True\n",
    ")\n",
    "\n",
    "trials = 3000\n",
    "target = Target.from_device(\"metal\")\n",
    "\n",
    "with target, tempfile.TemporaryDirectory() as tmp_dir:\n",
    "    seq = tvm.transform.Sequential(\n",
    "        [\n",
    "            relax.get_pipeline(\"zero\"),\n",
    "            relax.transform.MetaScheduleTuneTIR(work_dir=tmp_dir, max_trials_global=trials),\n",
    "            relax.transform.MetaScheduleApplyDatabase(work_dir=tmp_dir),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    mod = seq(mod)\n",
    "\n",
    "mod.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlc-audio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
