{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(N,  iH,  C),  (O,  wH,  C),   dtype,  stride, pads, groups, diff%\n",
      "MLX time in ms:  0.262115625\n",
      "Torch time in ms:  0.384521541\n",
      "(1,  62, 512), (512,  7, 512), float32,     1,    0,      1, +46.70%\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import math\n",
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "import mlx.core as mx\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "device_name = subprocess.check_output([\"sysctl\", \"-n\", \"machdep.cpu.brand_string\"])\n",
    "device_name = device_name.decode(\"utf-8\").strip(\"\\n\")\n",
    "\n",
    "N_warmup = 10\n",
    "N_iter_bench = 200\n",
    "N_iter_func = 5\n",
    "\n",
    "\n",
    "def bench(f, a, b):\n",
    "    for i in range(N_warmup):\n",
    "        f(a, b)\n",
    "    torch.mps.synchronize()\n",
    "\n",
    "    s = time.perf_counter_ns()\n",
    "    for i in range(N_iter_bench):\n",
    "        f(a, b)\n",
    "    e = time.perf_counter_ns()\n",
    "\n",
    "    avg_time_in_ms = (e - s) / (N_iter_bench * N_iter_func * 1e6)\n",
    "    return avg_time_in_ms\n",
    "\n",
    "\n",
    "def make_mx_conv_1D(strides=1, padding=0, groups=1):\n",
    "    def mx_conv_1D(a, b):\n",
    "        ys = []\n",
    "        for _ in range(N_iter_func):\n",
    "            y = mx.conv1d(a, b, stride=strides, padding=padding, groups=groups)\n",
    "            ys.append(y)\n",
    "        mx.eval(ys)\n",
    "        return ys\n",
    "\n",
    "    return mx_conv_1D\n",
    "\n",
    "\n",
    "def make_pt_conv_1D(strides=1, padding=0, groups=1):\n",
    "    @torch.no_grad()\n",
    "    def pt_conv_1D(a, b):\n",
    "        ys = []\n",
    "        for _ in range(N_iter_func):\n",
    "            y = torch.conv1d(a, b, stride=strides, padding=padding, groups=groups)\n",
    "            ys.append(y)\n",
    "        torch.mps.synchronize()\n",
    "        return ys\n",
    "\n",
    "    return pt_conv_1D\n",
    "\n",
    "\n",
    "def bench_shape(N, iH, C, wH, O, strides, padding, np_dtype, groups):\n",
    "    scale = 1.0 / math.sqrt(wH * C)\n",
    "    a_np = np.random.uniform(0, 0.5, (N, iH, C)).astype(np_dtype)\n",
    "    b_np = np.random.uniform(-scale, scale, (O, wH, int(C / groups))).astype(np_dtype)\n",
    "\n",
    "    a_mx = mx.array(a_np)\n",
    "    b_mx = mx.array(b_np)\n",
    "\n",
    "    a_pt = torch.from_numpy(a_np.transpose((0, 2, 1))).to(\"mps\")\n",
    "    b_pt = torch.from_numpy(b_np.transpose((0, 2, 1))).to(\"mps\")\n",
    "\n",
    "    torch.mps.synchronize()\n",
    "\n",
    "    f_mx = make_mx_conv_1D(strides, padding, groups)\n",
    "    f_pt = make_pt_conv_1D(strides, padding, groups)\n",
    "\n",
    "    time_torch = bench(f_pt, a_pt, b_pt)\n",
    "    time_mlx = bench(f_mx, a_mx, b_mx)\n",
    "\n",
    "    out_mx = mx.conv1d(a_mx, b_mx, stride=strides, padding=padding, groups=groups)\n",
    "    out_pt = torch.conv1d(\n",
    "        a_pt.to(\"cpu\"), b_pt.to(\"cpu\"), stride=strides, padding=padding, groups=groups\n",
    "    )\n",
    "    out_pt = torch.permute(out_pt, (0, 2, 1))\n",
    "    out_pt = out_pt.numpy(force=True)\n",
    "    # print(out_mx.shape, out_pt.shape)\n",
    "\n",
    "    atol = 2e-5 if np_dtype == np.float32 else 1e-4\n",
    "\n",
    "    if not np.allclose(out_pt, out_mx, atol=atol):\n",
    "        print(\n",
    "            f\"Failed at {(N, iH, C)}, {(O, wH, C)} [strides = {strides}, padding = {padding}, groups = {groups}] with max(|a - b|) = {np.max(np.abs(out_pt - out_mx))}\"\n",
    "        )\n",
    "\n",
    "    return time_mlx, time_torch\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"Run conv benchmarks\")\n",
    "\n",
    "    dtypes = (\"float32\",)\n",
    "    shapes = (\n",
    "        # (4, 32, 32, 5, 32, 1, 2, 1),\n",
    "        # (4, 32, 32, 5, 32, 1, 2, 2),\n",
    "        # (4, 32, 32, 5, 32, 1, 2, 4),\n",
    "        # (4, 32, 32, 5, 32, 1, 2, 8),\n",
    "        # (4, 32, 32, 5, 32, 1, 2, 8),\n",
    "        # (4, 32, 32, 5, 32, 1, 2, 16),\n",
    "        # (4, 32, 32, 5, 32, 1, 2, 32),\n",
    "        # (4, 32, 256, 5, 512, 1, 2, 2),\n",
    "        # (4, 32, 256, 5, 512, 1, 2, 128),\n",
    "        # (4, 32, 256, 5, 512, 1, 2, 256),\n",
    "        (1, 62, 512, 7, 512, 1, 0, 1),\n",
    "    )\n",
    "\n",
    "    for dtype in dtypes:\n",
    "        print(\"(N,  iH,  C),  (O,  wH,  C),   dtype,  stride, pads, groups, diff%\")\n",
    "        for N, iH, C, wH, O, strides, padding, groups in shapes:\n",
    "            np_dtype = getattr(np, dtype)\n",
    "            time_mlx, time_torch = bench_shape(\n",
    "                N, iH, C, wH, O, strides, padding, np_dtype, groups\n",
    "            )\n",
    "            print(\"MLX time in ms: \", time_mlx)\n",
    "            print(\"Torch time in ms: \", time_torch)\n",
    "            diff = time_torch / time_mlx - 1.0\n",
    "\n",
    "            print(\n",
    "                f\"({N}, {iH:3d}, {C:3d}), ({O:3d}, {wH:2d}, {C:3d}), {dtype}, {strides:5d}, {padding:4d}, {groups:6d}, {100. * diff:+5.2f}%\"\n",
    "            )\n",
    "\n",
    "            if time_mlx >= 2.0 * time_torch:\n",
    "                print(\"ATTENTION ^^^^^^^\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlc-audio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
