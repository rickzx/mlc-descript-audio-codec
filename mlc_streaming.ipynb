{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:09:16] /Users/cfruan/Documents/tvm-unity/src/target/llvm/llvm_instance.cc:226: Error: Using LLVM 19.1.1 with `-mcpu=apple-latest` is not valid in `-mtriple=arm64-apple-macos`, using default `-mcpu=generic`\n",
      "[23:09:16] /Users/cfruan/Documents/tvm-unity/src/target/llvm/llvm_instance.cc:226: Error: Using LLVM 19.1.1 with `-mcpu=apple-latest` is not valid in `-mtriple=arm64-apple-macos`, using default `-mcpu=generic`\n",
      "[23:09:16] /Users/cfruan/Documents/tvm-unity/src/target/llvm/llvm_instance.cc:226: Error: Using LLVM 19.1.1 with `-mcpu=apple-latest` is not valid in `-mtriple=arm64-apple-macos`, using default `-mcpu=generic`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import ir as I</span>\n",
       "<span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
       "<span style=\"color: #007979; font-style: italic\"># from tvm.script import relax as R</span>\n",
       "\n",
       "<span style=\"color: #AA22FF\">@I</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #0000FF; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">cached_padding_1d_crop</span>(var_x: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>handle, var_res: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>handle):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;op_pattern&quot;</span>: <span style=\"color: #008000\">0</span>})\n",
       "        b, c, out <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int32(), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int32(), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int32()\n",
       "        x <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>match_buffer(var_x, (b, c, out))\n",
       "        n <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int32()\n",
       "        res <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>match_buffer(var_res, (b, c, n))\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> bb, cc, nn <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(b, c, n):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;res_crop&quot;</span>):\n",
       "                vb, vc, vn <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSS&quot;</span>, [bb, cc, nn])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(x[vb, vc, vn])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(res[vb, vc, vn])\n",
       "                res[vb, vc, vn] <span style=\"color: #AA22FF; font-weight: bold\">=</span> x[vb, vc, vn]\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">cached_padding_1d_init</span>(var_cache: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>handle):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;op_pattern&quot;</span>: <span style=\"color: #008000\">0</span>})\n",
       "        b, c, p <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int32(), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int32(), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int32()\n",
       "        cache <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>match_buffer(var_cache, (b, c, p))\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> bb, cc, pp <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(b, c, p):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;cache_init&quot;</span>):\n",
       "                vb, vc, vp <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSS&quot;</span>, [bb, cc, pp])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads()\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(cache[vb, vc, vp])\n",
       "                cache[vb, vc, vp] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0.0</span>)\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">cached_padding_1d_update</span>(var_cache: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>handle, var_data: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>handle, var_res: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>handle):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;op_pattern&quot;</span>: <span style=\"color: #008000\">8</span>})\n",
       "        B, c, p <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int32(), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int32(), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int32()\n",
       "        cache <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>match_buffer(var_cache, (B, c, p))\n",
       "        b, n <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int32(), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int32()\n",
       "        data <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>match_buffer(var_data, (b, c, n))\n",
       "        out <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int32()\n",
       "        res <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>match_buffer(var_res, (b, c, out))\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> bb, cc, oo <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(b, c, out):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;res_update&quot;</span>):\n",
       "                vb, vc, vo <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSS&quot;</span>, [bb, cc, oo])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(cache[vb, vc, vo], data[vb, vc, vo <span style=\"color: #AA22FF; font-weight: bold\">-</span> p])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(res[vb, vc, vo])\n",
       "                res[vb, vc, vo] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>if_then_else(vo <span style=\"color: #AA22FF; font-weight: bold\">&lt;</span> p, cache[vb, vc, vo], data[vb, vc, vo <span style=\"color: #AA22FF; font-weight: bold\">-</span> p])\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> bb, cc, pp <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(b, c, p):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;cache_update&quot;</span>):\n",
       "                vb, vc, vp <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSS&quot;</span>, [bb, cc, pp])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(res[vb, vc, out <span style=\"color: #AA22FF; font-weight: bold\">-</span> p <span style=\"color: #AA22FF; font-weight: bold\">+</span> vp])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(cache[vb, vc, vp])\n",
       "                cache[vb, vc, vp] <span style=\"color: #AA22FF; font-weight: bold\">=</span> res[vb, vc, out <span style=\"color: #AA22FF; font-weight: bold\">-</span> p <span style=\"color: #AA22FF; font-weight: bold\">+</span> vp]\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">_initialize_effect</span>() <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tuple(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object):\n",
       "        cls <span style=\"color: #AA22FF; font-weight: bold\">=</span> Module\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            cache_cache: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_pure_packed(<span style=\"color: #BA2121\">&quot;vm.builtin.cached_padding_1d_create&quot;</span>, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_value(<span style=\"color: #008000\">3</span>), R<span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_value(<span style=\"color: #008000\">0</span>), R<span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_value(<span style=\"color: #008000\">1</span>), R<span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_value(<span style=\"color: #008000\">0</span>), cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>cached_padding_1d_init, cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>cached_padding_1d_update, cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>cached_padding_1d_crop, sinfo_args<span style=\"color: #AA22FF; font-weight: bold\">=</span>(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object,))\n",
       "            gv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tuple(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object) <span style=\"color: #AA22FF; font-weight: bold\">=</span> (cache_cache,)\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">forward</span>(x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), cache_cache: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tuple(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tuple(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">13</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)), R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tuple(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object)):\n",
       "        R<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;num_input&quot;</span>: <span style=\"color: #008000\">2</span>})\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">13</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_pure_packed(<span style=\"color: #BA2121\">&quot;vm.builtin.cached_padding_1d_update&quot;</span>, cache_cache, x, sinfo_args<span style=\"color: #AA22FF; font-weight: bold\">=</span>(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">13</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>),))\n",
       "            lv2: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_pure_packed(<span style=\"color: #BA2121\">&quot;vm.builtin.cached_padding_1d_view&quot;</span>, cache_cache, sinfo_args<span style=\"color: #AA22FF; font-weight: bold\">=</span>(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>),))\n",
       "            gv1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tuple(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tuple(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">13</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)), R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tuple(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object)) <span style=\"color: #AA22FF; font-weight: bold\">=</span> (lv1, lv2), (cache_cache,)\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv1)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv1\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.545322   0.26385272 0.30202466 0.08276599 0.20769066 0.913202\n",
      "   0.85411614 0.28952256 0.02826601 0.28631422]]]\n",
      "[[[0.         0.         0.         0.545322   0.26385272 0.30202466\n",
      "   0.08276599 0.20769066 0.913202   0.85411614 0.28952256 0.02826601\n",
      "   0.28631422]]]\n",
      "[[[0.28952256 0.02826601 0.28631422]]]\n",
      "[[[0.47812256 0.21356206 0.47955388 0.01061336 0.54981154 0.21186082\n",
      "   0.10509059 0.41574165 0.08226193 0.26996234]]]\n",
      "[[[0.28952256 0.02826601 0.28631422 0.47812256 0.21356206 0.47955388\n",
      "   0.01061336 0.54981154 0.21186082 0.10509059 0.41574165 0.08226193\n",
      "   0.26996234]]]\n",
      "[[[0.41574165 0.08226193 0.26996234]]]\n"
     ]
    }
   ],
   "source": [
    "from mlc_dac.streaming import CachedPadding1d\n",
    "from tvm import relax, topi\n",
    "from tvm.script import ir as I\n",
    "from tvm.script import relax as R\n",
    "from tvm.script import tir as T\n",
    "from tvm.relax.frontend import nn\n",
    "import tvm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class StreamingConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        self.cache = CachedPadding1d(3, False, 1)\n",
    "\n",
    "    def forward(self, x: nn.Tensor):\n",
    "        y = self.cache(x)\n",
    "        return y, self.cache.view(1)\n",
    "    \n",
    "mod, params = StreamingConv().export_tvm(\n",
    "    {\n",
    "        \"forward\": {\n",
    "            \"x\": nn.spec.Tensor([1, 1, 10], \"float32\"),\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "device = tvm.device(\"metal\")\n",
    "target = tvm.target.Target.from_device(device)\n",
    "\n",
    "with target:\n",
    "    mod = tvm.ir.transform.Sequential(\n",
    "        [\n",
    "            relax.get_pipeline(\"zero\"),\n",
    "        ]\n",
    "    )(mod)\n",
    "\n",
    "mod.show()\n",
    "\n",
    "ex = relax.build(mod, \"llvm\")\n",
    "vm = relax.VirtualMachine(ex, tvm.cpu())\n",
    "effects = vm[\"_initialize_effect\"]()\n",
    "\n",
    "x = tvm.nd.array(np.random.rand(1, 1, 10).astype(\"float32\"))\n",
    "print(x.asnumpy())\n",
    "o1, o2 = vm[\"forward\"](x, *effects)[0]\n",
    "print(o1.asnumpy())\n",
    "print(o2.asnumpy())\n",
    "\n",
    "x = tvm.nd.array(np.random.rand(1, 1, 10).astype(\"float32\"))\n",
    "print(x.asnumpy())\n",
    "o1, o2 = vm[\"forward\"](x, *effects)[0]\n",
    "print(o1.asnumpy())\n",
    "print(o2.asnumpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 1000)\n",
      "(1, 10, 1000)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tvm\n",
    "from tvm import relax\n",
    "from tvm.relax.frontend import nn\n",
    "from tvm.target import Target\n",
    "from tvm import dlight as dl\n",
    "\n",
    "\n",
    "from mlc_dac.layers import CachedConv1d\n",
    "\n",
    "cached_conv = CachedConv1d(5, 10, 3, padding=1)\n",
    "\n",
    "mod_cached, params_cached = cached_conv.export_tvm(\n",
    "    {\"forward\": {\"x\": nn.spec.Tensor((1, 5, 1000), \"float32\")}}, debug=True\n",
    ")\n",
    "\n",
    "mod, params = nn.Conv1D(5, 10, 3, padding=1).export_tvm(\n",
    "    {\"forward\": {\"x\": nn.spec.Tensor((1, 5, 1000), \"float32\")}}, debug=True\n",
    ")\n",
    "\n",
    "data = np.random.rand(1, 5, 1000).astype(\"float32\")\n",
    "weight = np.random.rand(10, 5, 3).astype(\"float32\")\n",
    "bias = np.random.rand(10).astype(\"float32\")\n",
    "\n",
    "seq = tvm.transform.Sequential(\n",
    "    [\n",
    "        tvm.relax.transform.LegalizeOps(),\n",
    "        dl.ApplyDefaultSchedule(\n",
    "            dl.gpu.Fallback(),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "device = tvm.metal()\n",
    "target = Target.from_device(device)\n",
    "with target:\n",
    "    mod_cached = seq(mod_cached)\n",
    "ex = relax.build(mod_cached, target)\n",
    "device = tvm.metal()\n",
    "\n",
    "vm = relax.VirtualMachine(ex, device)\n",
    "tvm_data = tvm.nd.array(data, device=device)\n",
    "params = [weight, bias]\n",
    "params = [tvm.nd.array(param, device=device) for param in params]\n",
    "\n",
    "effects = vm[\"_initialize_effect\"]()\n",
    "output_tvm_cached = vm[\"forward\"](tvm_data, *effects, *params)[0]\n",
    "\n",
    "seq = tvm.transform.Sequential(\n",
    "    [\n",
    "        tvm.relax.transform.LegalizeOps(),\n",
    "        dl.ApplyDefaultSchedule(\n",
    "            dl.gpu.Fallback(),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "device = tvm.metal()\n",
    "target = Target.from_device(device)\n",
    "with target:\n",
    "    mod = seq(mod)\n",
    "ex = relax.build(mod, target)\n",
    "device = tvm.metal()\n",
    "\n",
    "vm = relax.VirtualMachine(ex, device)\n",
    "tvm_data = tvm.nd.array(data, device=device)\n",
    "params = [weight, bias]\n",
    "params = [tvm.nd.array(param, device=device) for param in params]\n",
    "\n",
    "effects = vm[\"_initialize_effect\"]()\n",
    "output_tvm = vm[\"forward\"](tvm_data, *effects, *params)[0]\n",
    "\n",
    "print(output_tvm_cached.asnumpy().shape)\n",
    "print(output_tvm.asnumpy().shape)\n",
    "print(\n",
    "    np.allclose(\n",
    "        output_tvm.asnumpy()[..., : -cached_conv.cumulative_delay],\n",
    "        output_tvm_cached.asnumpy()[..., cached_conv.cumulative_delay :],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 1000)\n",
      "(1, 10, 1000)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tvm\n",
    "from tvm import relax\n",
    "from tvm.relax.frontend import nn\n",
    "from tvm.target import Target\n",
    "from tvm import dlight as dl\n",
    "\n",
    "from mlc_dac.layers import CachedConvTranspose1d\n",
    "\n",
    "cached_conv = CachedConvTranspose1d(5, 10, 3, padding=1)\n",
    "\n",
    "mod_cached, params_cached = cached_conv.export_tvm(\n",
    "    {\"forward\": {\"x\": nn.spec.Tensor((1, 5, 1000), \"float32\")}}, debug=True\n",
    ")\n",
    "\n",
    "mod, params = nn.ConvTranspose1D(5, 10, 3, padding=1).export_tvm(\n",
    "    {\"forward\": {\"x\": nn.spec.Tensor((1, 5, 1000), \"float32\")}}, debug=True\n",
    ")\n",
    "\n",
    "data = np.random.rand(1, 5, 1000).astype(\"float32\")\n",
    "weight = np.random.rand(5, 10, 3).astype(\"float32\")\n",
    "bias = np.random.rand(10).astype(\"float32\")\n",
    "\n",
    "seq = tvm.transform.Sequential(\n",
    "    [\n",
    "        tvm.relax.transform.LegalizeOps(),\n",
    "        dl.ApplyDefaultSchedule(\n",
    "            dl.gpu.Fallback(),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "device = tvm.metal()\n",
    "target = Target.from_device(device)\n",
    "with target:\n",
    "    mod_cached = seq(mod_cached)\n",
    "ex = relax.build(mod_cached, target)\n",
    "device = tvm.metal()\n",
    "\n",
    "vm = relax.VirtualMachine(ex, device)\n",
    "tvm_data = tvm.nd.array(data, device=device)\n",
    "params = [weight, bias]\n",
    "params = [tvm.nd.array(param, device=device) for param in params]\n",
    "\n",
    "effects = vm[\"_initialize_effect\"]()\n",
    "output_tvm_cached = vm[\"forward\"](tvm_data, *effects, *params)[0]\n",
    "\n",
    "seq = tvm.transform.Sequential(\n",
    "    [\n",
    "        tvm.relax.transform.LegalizeOps(),\n",
    "        dl.ApplyDefaultSchedule(\n",
    "            dl.gpu.Fallback(),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "device = tvm.metal()\n",
    "target = Target.from_device(device)\n",
    "with target:\n",
    "    mod = seq(mod)\n",
    "ex = relax.build(mod, target)\n",
    "device = tvm.metal()\n",
    "\n",
    "vm = relax.VirtualMachine(ex, device)\n",
    "tvm_data = tvm.nd.array(data, device=device)\n",
    "params = [weight, bias]\n",
    "params = [tvm.nd.array(param, device=device) for param in params]\n",
    "\n",
    "effects = vm[\"_initialize_effect\"]()\n",
    "output_tvm = vm[\"forward\"](tvm_data, *effects, *params)[0]\n",
    "\n",
    "print(output_tvm_cached.asnumpy().shape)\n",
    "print(output_tvm.asnumpy().shape)\n",
    "\n",
    "print(\n",
    "    np.allclose(\n",
    "        output_tvm.asnumpy()[..., : -cached_conv.cumulative_delay],\n",
    "        output_tvm_cached.asnumpy()[..., cached_conv.cumulative_delay :],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 993)\n",
      "(1, 10, 993)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tvm\n",
    "from tvm import relax\n",
    "from tvm.relax.frontend import nn\n",
    "from tvm.target import Target\n",
    "from tvm import dlight as dl\n",
    "\n",
    "from mlc_dac.layers import CachedWNConv1d, WNConv1d\n",
    "\n",
    "cached_conv = CachedWNConv1d(5, 10, 10, padding=1)\n",
    "\n",
    "mod_cached, params_cached = cached_conv.export_tvm(\n",
    "    {\"forward\": {\"x\": nn.spec.Tensor((1, 5, 1000), \"float32\")}}, debug=True\n",
    ")\n",
    "\n",
    "mod, params = WNConv1d(5, 10, 10, padding=1).export_tvm(\n",
    "    {\"forward\": {\"x\": nn.spec.Tensor((1, 5, 1000), \"float32\")}}, debug=True\n",
    ")\n",
    "\n",
    "data = np.random.rand(1, 5, 1000).astype(\"float32\")\n",
    "weight_g_data = np.random.rand(10, 1, 1).astype(\"float32\")\n",
    "weight_v_data = np.random.rand(10, 5, 10).astype(\"float32\")\n",
    "bias_data = np.random.rand(10).astype(\"float32\")\n",
    "\n",
    "target = Target.from_device(\"metal\")\n",
    "with target:\n",
    "    mod_cached = relax.transform.LegalizeOps()(mod_cached)\n",
    "    mod_cached = dl.ApplyDefaultSchedule(\n",
    "        dl.gpu.Fallback(),\n",
    "    )(mod_cached)\n",
    "ex = relax.build(mod_cached, target)\n",
    "device = tvm.metal()\n",
    "\n",
    "vm = relax.VirtualMachine(ex, device)\n",
    "tvm_data = tvm.nd.array(data, device=device)\n",
    "params = [weight_g_data, weight_v_data, bias_data]\n",
    "params = [tvm.nd.array(param, device=device) for param in params]\n",
    "\n",
    "effects = vm[\"_initialize_effect\"]()\n",
    "out_cached = vm[\"forward\"](tvm_data, *effects, *params)[0].numpy()\n",
    "\n",
    "target = Target.from_device(\"metal\")\n",
    "with target:\n",
    "    mod = relax.transform.LegalizeOps()(mod)\n",
    "    mod = dl.ApplyDefaultSchedule(\n",
    "        dl.gpu.Fallback(),\n",
    "    )(mod)\n",
    "ex = relax.build(mod, target)\n",
    "device = tvm.metal()\n",
    "\n",
    "vm = relax.VirtualMachine(ex, device)\n",
    "tvm_data = tvm.nd.array(data, device=device)\n",
    "params = [weight_g_data, weight_v_data, bias_data]\n",
    "params = [tvm.nd.array(param, device=device) for param in params]\n",
    "\n",
    "effects = vm[\"_initialize_effect\"]()\n",
    "out = vm[\"forward\"](tvm_data, *effects, *params)[0].numpy()\n",
    "\n",
    "print(out_cached.shape)\n",
    "print(out.shape)\n",
    "print(np.allclose(out_cached[..., cached_conv.cumulative_delay :], out[..., : -cached_conv.cumulative_delay]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 1007)\n",
      "(1, 10, 1007)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tvm\n",
    "from tvm import relax\n",
    "from tvm.relax.frontend import nn\n",
    "from tvm.target import Target\n",
    "from tvm import dlight as dl\n",
    "\n",
    "from mlc_dac.layers import CachedWNConvTranspose1d, WNConvTranspose1d\n",
    "\n",
    "cached_conv = CachedWNConvTranspose1d(5, 10, 10, padding=1)\n",
    "\n",
    "mod_cached, params_cached = cached_conv.export_tvm(\n",
    "    {\"forward\": {\"x\": nn.spec.Tensor((1, 5, 1000), \"float32\")}}, debug=True\n",
    ")\n",
    "\n",
    "mod, params = WNConvTranspose1d(5, 10, 10, padding=1).export_tvm(\n",
    "    {\"forward\": {\"x\": nn.spec.Tensor((1, 5, 1000), \"float32\")}}, debug=True\n",
    ")\n",
    "\n",
    "data = np.random.rand(1, 5, 1000).astype(\"float32\")\n",
    "weight_g_data = np.random.rand(5, 1, 1).astype(\"float32\")\n",
    "weight_v_data = np.random.rand(5, 10, 10).astype(\"float32\")\n",
    "bias_data = np.random.rand(10).astype(\"float32\")\n",
    "\n",
    "target = Target.from_device(\"metal\")\n",
    "with target:\n",
    "    mod_cached = relax.transform.LegalizeOps()(mod_cached)\n",
    "    mod_cached = dl.ApplyDefaultSchedule(\n",
    "        dl.gpu.Fallback(),\n",
    "    )(mod_cached)\n",
    "ex = relax.build(mod_cached, target)\n",
    "device = tvm.metal()\n",
    "\n",
    "vm = relax.VirtualMachine(ex, device)\n",
    "tvm_data = tvm.nd.array(data, device=device)\n",
    "params = [weight_g_data, weight_v_data, bias_data]\n",
    "params = [tvm.nd.array(param, device=device) for param in params]\n",
    "\n",
    "effects = vm[\"_initialize_effect\"]()\n",
    "out_cached = vm[\"forward\"](tvm_data, *effects, *params)[0].numpy()\n",
    "\n",
    "target = Target.from_device(\"metal\")\n",
    "with target:\n",
    "    mod = relax.transform.LegalizeOps()(mod)\n",
    "    mod = dl.ApplyDefaultSchedule(\n",
    "        dl.gpu.Fallback(),\n",
    "    )(mod)\n",
    "ex = relax.build(mod, target)\n",
    "device = tvm.metal()\n",
    "\n",
    "vm = relax.VirtualMachine(ex, device)\n",
    "tvm_data = tvm.nd.array(data, device=device)\n",
    "params = [weight_g_data, weight_v_data, bias_data]\n",
    "params = [tvm.nd.array(param, device=device) for param in params]\n",
    "\n",
    "effects = vm[\"_initialize_effect\"]()\n",
    "out = vm[\"forward\"](tvm_data, *effects, *params)[0].numpy()\n",
    "\n",
    "print(out_cached.shape)\n",
    "print(out.shape)\n",
    "print(np.allclose(out_cached[..., cached_conv.cumulative_delay :], out[..., : -cached_conv.cumulative_delay]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import ir as I</span>\n",
       "<span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
       "<span style=\"color: #007979; font-style: italic\"># from tvm.script import relax as R</span>\n",
       "\n",
       "<span style=\"color: #AA22FF\">@I</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #0000FF; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">cached_padding_1d_crop</span>(var_x: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>handle, var_res: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>handle):\n",
       "        b, c, out <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int32(), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int32(), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int32()\n",
       "        x <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>match_buffer(var_x, (b, c, out))\n",
       "        n <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int32()\n",
       "        res <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>match_buffer(var_res, (b, c, n))\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> bb, cc, nn <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(b, c, n):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;res_crop&quot;</span>):\n",
       "                vb, vc, vn <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSS&quot;</span>, [bb, cc, nn])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(x[vb, vc, vn])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(res[vb, vc, vn])\n",
       "                res[vb, vc, vn] <span style=\"color: #AA22FF; font-weight: bold\">=</span> x[vb, vc, vn]\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">cached_padding_1d_init</span>(var_cache: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>handle):\n",
       "        b, c, p <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int32(), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int32(), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int32()\n",
       "        cache <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>match_buffer(var_cache, (b, c, p))\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> bb, cc, pp <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(b, c, p):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;cache_init&quot;</span>):\n",
       "                vb, vc, vp <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSS&quot;</span>, [bb, cc, pp])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads()\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(cache[vb, vc, vp])\n",
       "                cache[vb, vc, vp] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0.0</span>)\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">cached_padding_1d_update</span>(var_cache: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>handle, var_data: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>handle, var_res: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>handle):\n",
       "        B, c, p <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int32(), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int32(), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int32()\n",
       "        cache <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>match_buffer(var_cache, (B, c, p))\n",
       "        b, n <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int32(), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int32()\n",
       "        data <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>match_buffer(var_data, (b, c, n))\n",
       "        out <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int32()\n",
       "        res <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>match_buffer(var_res, (b, c, out))\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> bb, cc, oo <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(b, c, out):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;res_update&quot;</span>):\n",
       "                vb, vc, vo <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSS&quot;</span>, [bb, cc, oo])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(cache[vb, vc, vo], data[vb, vc, vo <span style=\"color: #AA22FF; font-weight: bold\">-</span> p])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(res[vb, vc, vo])\n",
       "                res[vb, vc, vo] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>if_then_else(vo <span style=\"color: #AA22FF; font-weight: bold\">&lt;</span> p, cache[vb, vc, vo], data[vb, vc, vo <span style=\"color: #AA22FF; font-weight: bold\">-</span> p])\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> bb, cc, pp <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(b, c, p):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;cache_update&quot;</span>):\n",
       "                vb, vc, vp <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSS&quot;</span>, [bb, cc, pp])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(res[vb, vc, out <span style=\"color: #AA22FF; font-weight: bold\">-</span> p <span style=\"color: #AA22FF; font-weight: bold\">+</span> vp])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(cache[vb, vc, vp])\n",
       "                cache[vb, vc, vp] <span style=\"color: #AA22FF; font-weight: bold\">=</span> res[vb, vc, out <span style=\"color: #AA22FF; font-weight: bold\">-</span> p <span style=\"color: #AA22FF; font-weight: bold\">+</span> vp]\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">_initialize_effect</span>() <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tuple(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object):\n",
       "        cls <span style=\"color: #AA22FF; font-weight: bold\">=</span> Module\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            _io: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>null_value()\n",
       "            branches_0_cache_cache: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_pure_packed(<span style=\"color: #BA2121\">&quot;vm.builtin.cached_padding_1d_create&quot;</span>, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_value(<span style=\"color: #008000\">4</span>), R<span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_value(<span style=\"color: #008000\">0</span>), R<span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_value(<span style=\"color: #008000\">32</span>), R<span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_value(<span style=\"color: #008000\">0</span>), cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>cached_padding_1d_init, cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>cached_padding_1d_update, cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>cached_padding_1d_crop, sinfo_args<span style=\"color: #AA22FF; font-weight: bold\">=</span>(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object,))\n",
       "            branches_0_downsampling_delay_cache: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_pure_packed(<span style=\"color: #BA2121\">&quot;vm.builtin.cached_padding_1d_create&quot;</span>, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_value(<span style=\"color: #008000\">0</span>), R<span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_value(<span style=\"color: #008000\">1</span>), R<span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_value(<span style=\"color: #008000\">32</span>), R<span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_value(<span style=\"color: #008000\">0</span>), cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>cached_padding_1d_init, cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>cached_padding_1d_update, cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>cached_padding_1d_crop, sinfo_args<span style=\"color: #AA22FF; font-weight: bold\">=</span>(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object,))\n",
       "            paddings_0_cache: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_pure_packed(<span style=\"color: #BA2121\">&quot;vm.builtin.cached_padding_1d_create&quot;</span>, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_value(<span style=\"color: #008000\">0</span>), R<span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_value(<span style=\"color: #008000\">1</span>), R<span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_value(<span style=\"color: #008000\">32</span>), R<span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_value(<span style=\"color: #008000\">0</span>), cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>cached_padding_1d_init, cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>cached_padding_1d_update, cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>cached_padding_1d_crop, sinfo_args<span style=\"color: #AA22FF; font-weight: bold\">=</span>(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object,))\n",
       "            paddings_1_cache: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_pure_packed(<span style=\"color: #BA2121\">&quot;vm.builtin.cached_padding_1d_create&quot;</span>, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_value(<span style=\"color: #008000\">2</span>), R<span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_value(<span style=\"color: #008000\">1</span>), R<span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_value(<span style=\"color: #008000\">32</span>), R<span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_value(<span style=\"color: #008000\">0</span>), cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>cached_padding_1d_init, cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>cached_padding_1d_update, cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>cached_padding_1d_crop, sinfo_args<span style=\"color: #AA22FF; font-weight: bold\">=</span>(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object,))\n",
       "            lv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tuple(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object) <span style=\"color: #AA22FF; font-weight: bold\">=</span> _io, branches_0_cache_cache, branches_0_downsampling_delay_cache, paddings_0_cache, paddings_1_cache\n",
       "            gv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tuple(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object) <span style=\"color: #AA22FF; font-weight: bold\">=</span> lv\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">forward</span>(x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), _io: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object, branches_0_cache_cache: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object, branches_0_downsampling_delay_cache: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object, paddings_0_cache: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object, paddings_1_cache: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object, branches_0_weight: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">5</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), branches_0_bias: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>,), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tuple(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tuple(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)), R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tuple(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object)):\n",
       "        R<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;num_input&quot;</span>: <span style=\"color: #008000\">6</span>})\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_pure_packed(<span style=\"color: #BA2121\">&quot;vm.builtin.cached_padding_1d_update&quot;</span>, paddings_0_cache, x, sinfo_args<span style=\"color: #AA22FF; font-weight: bold\">=</span>(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>),))\n",
       "            lv2: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_pure_packed(<span style=\"color: #BA2121\">&quot;vm.builtin.cached_padding_1d_update&quot;</span>, branches_0_downsampling_delay_cache, lv1, sinfo_args<span style=\"color: #AA22FF; font-weight: bold\">=</span>(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>),))\n",
       "            lv3: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">14</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_pure_packed(<span style=\"color: #BA2121\">&quot;vm.builtin.cached_padding_1d_update&quot;</span>, branches_0_cache_cache, lv2, sinfo_args<span style=\"color: #AA22FF; font-weight: bold\">=</span>(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">14</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>),))\n",
       "            lv4: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>nn<span style=\"color: #AA22FF; font-weight: bold\">.</span>conv1d(lv3, branches_0_weight, strides<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>], padding<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">0</span>, <span style=\"color: #008000\">0</span>], dilation<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>], groups<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, data_layout<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCW&quot;</span>, kernel_layout<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;OIW&quot;</span>, out_layout<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCW&quot;</span>, out_dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;void&quot;</span>)\n",
       "            lv5: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>reshape(branches_0_bias, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>shape([<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>]))\n",
       "            conv1d: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>add(lv4, lv5)\n",
       "            lv6: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_pure_packed(<span style=\"color: #BA2121\">&quot;vm.builtin.cached_padding_1d_update&quot;</span>, paddings_1_cache, x, sinfo_args<span style=\"color: #AA22FF; font-weight: bold\">=</span>(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>),))\n",
       "            gv1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tuple(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tuple(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)), R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tuple(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object)) <span style=\"color: #AA22FF; font-weight: bold\">=</span> (conv1d, lv6), (_io, branches_0_cache_cache, branches_0_downsampling_delay_cache, paddings_0_cache, paddings_1_cache)\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv1)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv1\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tvm\n",
    "from tvm import relax\n",
    "from tvm.relax.frontend import nn\n",
    "from tvm.target import Target\n",
    "from tvm import dlight as dl\n",
    "\n",
    "from mlc_dac.layers import AlignBranches, CachedConv1d, Identity\n",
    "\n",
    "conv = CachedConv1d(1, 1, 5, padding=2)\n",
    "model = AlignBranches(\n",
    "    conv,\n",
    "    Identity(),\n",
    "    delays=[conv.cumulative_delay, 0],\n",
    ")\n",
    "\n",
    "mod, params = model.export_tvm(\n",
    "    {\"forward\": {\"x\": nn.spec.Tensor((1, 1, 10), \"float32\")}}, debug=True\n",
    ")\n",
    "mod.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:37:59] /Users/cfruan/Documents/tvm-unity/src/target/llvm/llvm_instance.cc:226: Error: Using LLVM 19.1.1 with `-mcpu=apple-latest` is not valid in `-mtriple=arm64-apple-macos`, using default `-mcpu=generic`\n",
      "[23:37:59] /Users/cfruan/Documents/tvm-unity/src/target/llvm/llvm_instance.cc:226: Error: Using LLVM 19.1.1 with `-mcpu=apple-latest` is not valid in `-mtriple=arm64-apple-macos`, using default `-mcpu=generic`\n",
      "[23:37:59] /Users/cfruan/Documents/tvm-unity/src/target/llvm/llvm_instance.cc:226: Error: Using LLVM 19.1.1 with `-mcpu=apple-latest` is not valid in `-mtriple=arm64-apple-macos`, using default `-mcpu=generic`\n"
     ]
    }
   ],
   "source": [
    "from mlc_dac.dac import DAC\n",
    "import numpy as np\n",
    "import tvm\n",
    "from tvm import relax\n",
    "from tvm.relax.frontend import nn\n",
    "from tvm.target import Target\n",
    "from tvm import dlight as dl\n",
    "\n",
    "mod_from_relax, params_from_relax = DAC().export_tvm(\n",
    "    {\"encode\": {\"audio_data\": nn.spec.Tensor((32, 1, 100000), \"float32\")}}, debug=True\n",
    ")\n",
    "\n",
    "seq = tvm.transform.Sequential(\n",
    "    [\n",
    "        tvm.relax.transform.LegalizeOps(),\n",
    "        tvm.relax.transform.AnnotateTIROpPattern(),\n",
    "        tvm.relax.transform.FoldConstant(),\n",
    "        tvm.relax.transform.FuseOps(),\n",
    "        tvm.relax.transform.FuseTIR(),\n",
    "        dl.ApplyDefaultSchedule(\n",
    "            # dl.gpu.Matmul(),\n",
    "            dl.gpu.GEMV(),\n",
    "            dl.gpu.Reduction(),\n",
    "            dl.gpu.GeneralReduction(),\n",
    "            dl.gpu.Fallback(),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "target = Target.from_device(\"metal\")\n",
    "with target:\n",
    "    mod_from_relax = seq(mod_from_relax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlc-audio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
