{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cfruan/miniconda3/envs/mlc-audio/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:135: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.9988,  0.9286,  0.8645,  ...,  0.8869,  0.7973,  0.8903],\n",
      "         [-0.1705, -0.7351,  0.4765,  ..., -0.1090, -0.1078,  0.0302],\n",
      "         [-0.4289, -1.6530, -0.5824,  ..., -0.9791, -0.4523, -0.6140],\n",
      "         ...,\n",
      "         [-3.6225, -1.5333, -2.9127,  ..., -1.9451, -3.5091, -1.4743],\n",
      "         [ 0.4280,  0.5835,  0.6545,  ...,  0.5954,  0.4389,  0.8003],\n",
      "         [-1.1396, -1.8115, -0.7024,  ..., -1.7644, -1.3501, -0.7024]],\n",
      "\n",
      "        [[ 0.9899,  0.7915,  0.8645,  ...,  0.9607,  0.8546,  0.9808],\n",
      "         [-0.8788, -0.0732,  0.4765,  ..., -0.2098, -1.0007,  0.0928],\n",
      "         [-0.5386, -0.6403, -0.5824,  ..., -1.4164, -1.9763, -0.4482],\n",
      "         ...,\n",
      "         [-3.0648, -2.4138, -2.9127,  ..., -3.3440, -3.2999, -3.0438],\n",
      "         [ 0.1935,  0.4268,  0.6545,  ...,  0.6232,  0.8056,  0.6058],\n",
      "         [-1.5807, -1.2421, -0.7024,  ..., -2.1177, -1.9800, -1.4128]],\n",
      "\n",
      "        [[ 0.8903,  0.9075,  0.8546,  ...,  0.8645,  0.8645,  0.8451],\n",
      "         [ 0.0302, -0.5262, -1.0007,  ...,  0.4765,  0.4765, -0.4823],\n",
      "         [-0.6140, -1.0764, -1.9763,  ..., -0.5824, -0.5824, -1.5489],\n",
      "         ...,\n",
      "         [-1.4743, -1.0179, -3.2999,  ..., -2.9127, -2.9127, -3.0495],\n",
      "         [ 0.8003,  0.5308,  0.8056,  ...,  0.6545,  0.6545,  0.5146],\n",
      "         [-0.7024, -1.2589, -1.9800,  ..., -0.7024, -0.7024, -1.6266]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.0319,  0.8645,  0.8903,  ...,  0.8903,  0.8355,  0.9075],\n",
      "         [-0.2467,  0.4765,  0.0302,  ...,  0.0302,  0.4390, -0.5262],\n",
      "         [-1.1518, -0.5824, -0.6140,  ..., -0.6140,  0.2522, -1.0764],\n",
      "         ...,\n",
      "         [-2.9845, -2.9127, -1.4743,  ..., -1.4743, -3.5105, -1.0179],\n",
      "         [ 0.4124,  0.6545,  0.8003,  ...,  0.8003,  0.4591,  0.5308],\n",
      "         [-1.7412, -0.7024, -0.7024,  ..., -0.7024, -0.6514, -1.2589]],\n",
      "\n",
      "        [[ 0.9286,  0.8630,  0.8546,  ...,  0.8903,  0.9075,  0.8645],\n",
      "         [-0.7351, -0.6112, -1.0007,  ...,  0.0302, -0.5262,  0.4765],\n",
      "         [-1.6530, -1.1570, -1.9763,  ..., -0.6140, -1.0764, -0.5824],\n",
      "         ...,\n",
      "         [-1.5333, -0.9267, -3.2999,  ..., -1.4743, -1.0179, -2.9127],\n",
      "         [ 0.5835,  0.4052,  0.8056,  ...,  0.8003,  0.5308,  0.6545],\n",
      "         [-1.8115, -2.1208, -1.9800,  ..., -0.7024, -1.2589, -0.7024]],\n",
      "\n",
      "        [[ 0.7973,  0.8963,  0.8645,  ...,  0.7973,  0.9634,  0.8915],\n",
      "         [-0.1078, -0.4160,  0.4765,  ..., -0.1078,  0.1853, -0.4765],\n",
      "         [-0.4523, -1.1876, -0.5824,  ..., -0.4523, -1.5675, -1.6542],\n",
      "         ...,\n",
      "         [-3.5091, -3.8935, -2.9127,  ..., -3.5091, -1.8993, -3.9653],\n",
      "         [ 0.4389,  0.8838,  0.6545,  ...,  0.4389,  0.6120,  0.4624],\n",
      "         [-1.3501, -1.8294, -0.7024,  ..., -1.3501, -1.8467, -2.1276]]],\n",
      "       grad_fn=<ConvolutionBackward0>) tensor([[632, 547, 142,  ..., 384, 272, 551],\n",
      "        [802,  61, 142,  ...,  39, 311, 938],\n",
      "        [551, 356, 311,  ..., 142, 142, 936],\n",
      "        ...,\n",
      "        [ 71, 142, 551,  ..., 551,  40, 356],\n",
      "        [547, 373, 311,  ..., 551, 356, 142],\n",
      "        [272, 722, 142,  ..., 272, 647, 461]])\n"
     ]
    }
   ],
   "source": [
    "from typing import Union\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange\n",
    "from torch.nn.utils import weight_norm\n",
    "\n",
    "def WNConv1d(*args, **kwargs):\n",
    "    return weight_norm(nn.Conv1d(*args, **kwargs))\n",
    "\n",
    "class VectorQuantize(nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of VQ similar to Karpathy's repo:\n",
    "    https://github.com/karpathy/deep-vector-quantization\n",
    "    Additionally uses following tricks from Improved VQGAN\n",
    "    (https://arxiv.org/pdf/2110.04627.pdf):\n",
    "        1. Factorized codes: Perform nearest neighbor lookup in low-dimensional space\n",
    "            for improved codebook usage\n",
    "        2. l2-normalized codes: Converts euclidean distance to cosine similarity which\n",
    "            improves training stability\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim: int, codebook_size: int, codebook_dim: int):\n",
    "        super().__init__()\n",
    "        self.codebook_size = codebook_size\n",
    "        self.codebook_dim = codebook_dim\n",
    "\n",
    "        self.in_proj = WNConv1d(input_dim, codebook_dim, kernel_size=1)\n",
    "        self.out_proj = WNConv1d(codebook_dim, input_dim, kernel_size=1)\n",
    "        self.codebook = nn.Embedding(codebook_size, codebook_dim)\n",
    "\n",
    "    def forward(self, z):\n",
    "        \"\"\"Quantized the input tensor using a fixed codebook and returns\n",
    "        the corresponding codebook vectors\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        z : Tensor[B x D x T]\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tensor[B x D x T]\n",
    "            Quantized continuous representation of input\n",
    "        Tensor[1]\n",
    "            Commitment loss to train encoder to predict vectors closer to codebook\n",
    "            entries\n",
    "        Tensor[1]\n",
    "            Codebook loss to update the codebook\n",
    "        Tensor[B x T]\n",
    "            Codebook indices (quantized discrete representation of input)\n",
    "        Tensor[B x D x T]\n",
    "            Projected latents (continuous representation of input before quantization)\n",
    "        \"\"\"\n",
    "\n",
    "        # Factorized codes (ViT-VQGAN) Project input into low-dimensional space\n",
    "        z_e = self.in_proj(z)  # z_e : (B x D x T)\n",
    "        z_q, indices = self.decode_latents(z_e)\n",
    "\n",
    "        commitment_loss = F.mse_loss(z_e, z_q.detach(), reduction=\"none\").mean([1, 2])\n",
    "        codebook_loss = F.mse_loss(z_q, z_e.detach(), reduction=\"none\").mean([1, 2])\n",
    "\n",
    "        z_q = (\n",
    "            z_e + (z_q - z_e).detach()\n",
    "        )  # noop in forward pass, straight-through gradient estimator in backward pass\n",
    "\n",
    "        z_q = self.out_proj(z_q)\n",
    "\n",
    "        return z_q, commitment_loss, codebook_loss, indices, z_e\n",
    "\n",
    "    def embed_code(self, embed_id):\n",
    "        ans = F.embedding(embed_id, self.codebook.weight)\n",
    "        return ans\n",
    "\n",
    "    def decode_code(self, embed_id):\n",
    "        return self.embed_code(embed_id).transpose(1, 2)\n",
    "\n",
    "    def decode_latents(self, latents):\n",
    "        encodings = rearrange(latents, \"b d t -> (b t) d\")\n",
    "        codebook = self.codebook.weight  # codebook: (N x D)\n",
    "\n",
    "        # L2 normalize encodings and codebook (ViT-VQGAN)\n",
    "        encodings = F.normalize(encodings)\n",
    "        codebook = F.normalize(codebook)\n",
    "\n",
    "        # Compute euclidean distance with codebook\n",
    "        dist = (\n",
    "            encodings.pow(2).sum(1, keepdim=True)\n",
    "            - 2 * encodings @ codebook.t()\n",
    "            + codebook.pow(2).sum(1, keepdim=True).t()\n",
    "        )\n",
    "        indices = rearrange((-dist).max(1)[1], \"(b t) -> b t\", b=latents.size(0))\n",
    "        z_q = self.decode_code(indices)\n",
    "        return z_q, indices\n",
    "\n",
    "torch.manual_seed(0)\n",
    "vq = VectorQuantize(1024, 1024, 8)\n",
    "vq.in_proj.weight_v.data = torch.randn(8, 1024, 1)\n",
    "vq.in_proj.weight_g.data = torch.randn(8, 1, 1)\n",
    "vq.in_proj.bias.data = torch.randn(8)\n",
    "vq.out_proj.weight_v.data = torch.randn(1024, 8, 1)\n",
    "vq.out_proj.weight_g.data = torch.randn(1024, 1, 1)\n",
    "vq.out_proj.bias.data = torch.randn(1024)\n",
    "vq.codebook.weight.data = torch.randn(1024, 8)\n",
    "\n",
    "z = torch.randn(32, 1024, 500)\n",
    "z_q, commitment_loss, codebook_loss, indices, z_e = vq(z)\n",
    "print(z_q, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-3.8284, -3.7353, -3.2694,  ..., -4.2950, -3.4027, -4.8893],\n",
      "         [-0.5032, -3.1676, -1.6385,  ..., -2.0904, -2.8227, -0.1386],\n",
      "         [ 0.5786, -0.2436, -0.4937,  ...,  1.3624,  1.1955, -0.2150],\n",
      "         ...,\n",
      "         [-2.7138, -2.9814, -3.2482,  ..., -2.6789, -2.8203, -2.7572],\n",
      "         [-0.4085, -0.2236, -0.1695,  ..., -1.7220, -0.4804, -0.7997],\n",
      "         [ 0.2923, -0.1119,  0.0231,  ...,  1.4829,  1.1780,  0.3640]],\n",
      "\n",
      "        [[-1.7458, -4.6101, -2.9354,  ..., -1.5002, -5.4848, -2.7086],\n",
      "         [-0.8326, -0.8330, -0.9082,  ..., -0.7709, -2.2841, -0.4977],\n",
      "         [ 3.0759,  0.1574,  0.9528,  ...,  1.3162,  0.3702,  1.2299],\n",
      "         ...,\n",
      "         [-2.7903, -3.0200, -2.9933,  ..., -2.3979, -2.5885, -2.9738],\n",
      "         [-0.3413, -0.1408, -0.0683,  ...,  0.7651, -0.9241, -0.0609],\n",
      "         [ 0.1140, -0.3490,  0.1787,  ...,  0.0482,  0.8981, -0.1373]],\n",
      "\n",
      "        [[-3.4563, -3.7545, -5.5988,  ..., -6.0925, -4.1387, -3.4020],\n",
      "         [-2.0591, -2.2037, -2.6103,  ..., -0.5445, -1.3141, -2.4954],\n",
      "         [-1.2233,  2.1199,  0.1889,  ...,  1.1289,  2.2967,  1.7367],\n",
      "         ...,\n",
      "         [-3.1104, -2.9284, -2.9658,  ..., -2.5406, -2.7767, -2.9584],\n",
      "         [-0.6257, -1.3208, -0.9731,  ..., -1.1533, -0.4218, -1.3818],\n",
      "         [ 0.4982,  1.1430,  0.6208,  ...,  0.8875,  0.7022,  1.3693]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.7348, -3.2622, -3.1555,  ..., -3.2694, -4.3813, -4.2014],\n",
      "         [-1.4312, -1.6275, -1.3123,  ..., -1.6385, -2.3615, -3.0184],\n",
      "         [-0.2063,  1.6832, -0.3124,  ..., -0.4937, -0.1190,  0.5776],\n",
      "         ...,\n",
      "         [-2.8603, -2.4792, -2.8709,  ..., -3.2482, -2.9259, -2.8255],\n",
      "         [-0.0671, -0.1969, -0.1206,  ..., -0.1695,  0.2845, -1.3806],\n",
      "         [ 0.3901, -0.4133,  0.3003,  ...,  0.0231, -0.0912,  1.5806]],\n",
      "\n",
      "        [[-4.2014, -5.0317, -5.4848,  ..., -4.2674, -3.8284, -2.8996],\n",
      "         [-3.0184, -0.9091, -2.2841,  ...,  0.4635, -0.5032, -1.1006],\n",
      "         [ 0.5776,  1.9225,  0.3702,  ..., -0.0367,  0.5786,  2.2126],\n",
      "         ...,\n",
      "         [-2.8255, -2.4972, -2.5885,  ..., -3.1723, -2.7138, -2.5591],\n",
      "         [-1.3806, -0.7620, -0.9241,  ..., -1.1819, -0.4085, -0.4273],\n",
      "         [ 1.5806,  0.8158,  0.8981,  ...,  0.3441,  0.2923,  1.0513]],\n",
      "\n",
      "        [[-3.7073, -3.5389, -2.3071,  ..., -3.7348, -3.1555, -3.1732],\n",
      "         [-0.9236, -2.9375, -1.5547,  ..., -1.4312, -1.3123, -0.3477],\n",
      "         [ 0.6510,  0.3313,  0.0562,  ..., -0.2063, -0.3124,  1.8325],\n",
      "         ...,\n",
      "         [-2.5104, -2.8697, -2.9084,  ..., -2.8603, -2.8709, -2.8088],\n",
      "         [-1.0492, -1.2589, -0.7553,  ..., -0.0671, -0.1206,  0.5251],\n",
      "         [ 1.6012,  1.7431,  0.5546,  ...,  0.3901,  0.3003, -0.7498]]],\n",
      "       grad_fn=<AddBackward0>) tensor([[[ 18, 309, 787,  ...,  18, 309, 223],\n",
      "         [208, 464, 709,  ..., 217, 817, 208]],\n",
      "\n",
      "        [[897, 487, 561,  ..., 250, 309, 952],\n",
      "         [273, 709, 208,  ..., 709,  11, 709]],\n",
      "\n",
      "        [[981, 952, 787,  ..., 223, 561, 561],\n",
      "         [709, 217,  11,  ..., 422, 422, 217]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[309, 261, 309,  ..., 787, 582, 309],\n",
      "         [208, 464, 709,  ..., 709, 709, 217]],\n",
      "\n",
      "        [[309,  18, 309,  ..., 368,  18,  15],\n",
      "         [217, 422,  11,  ..., 208, 208, 422]],\n",
      "\n",
      "        [[309, 309, 309,  ..., 309, 309, 952],\n",
      "         [100, 427, 235,  ..., 208, 709,  57]]])\n"
     ]
    }
   ],
   "source": [
    "from typing import Union\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ResidualVectorQuantize(nn.Module):\n",
    "    \"\"\"\n",
    "    Introduced in SoundStream: An end2end neural audio codec\n",
    "    https://arxiv.org/abs/2107.03312\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int = 512,\n",
    "        n_codebooks: int = 9,\n",
    "        codebook_size: int = 1024,\n",
    "        codebook_dim: Union[int, list] = 8,\n",
    "        quantizer_dropout: float = 0.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if isinstance(codebook_dim, int):\n",
    "            codebook_dim = [codebook_dim for _ in range(n_codebooks)]\n",
    "\n",
    "        self.n_codebooks = n_codebooks\n",
    "        self.codebook_dim = codebook_dim\n",
    "        self.codebook_size = codebook_size\n",
    "\n",
    "        self.quantizers = nn.ModuleList(\n",
    "            [\n",
    "                VectorQuantize(input_dim, codebook_size, codebook_dim[i])\n",
    "                for i in range(n_codebooks)\n",
    "            ]\n",
    "        )\n",
    "        self.quantizer_dropout = quantizer_dropout\n",
    "\n",
    "    def forward(self, z, n_quantizers: int = None):\n",
    "        \"\"\"Quantized the input tensor using a fixed set of `n` codebooks and returns\n",
    "        the corresponding codebook vectors\n",
    "        Parameters\n",
    "        ----------\n",
    "        z : Tensor[B x D x T]\n",
    "        n_quantizers : int, optional\n",
    "            No. of quantizers to use\n",
    "            (n_quantizers < self.n_codebooks ex: for quantizer dropout)\n",
    "            Note: if `self.quantizer_dropout` is True, this argument is ignored\n",
    "                when in training mode, and a random number of quantizers is used.\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            A dictionary with the following keys:\n",
    "\n",
    "            \"z\" : Tensor[B x D x T]\n",
    "                Quantized continuous representation of input\n",
    "            \"codes\" : Tensor[B x N x T]\n",
    "                Codebook indices for each codebook\n",
    "                (quantized discrete representation of input)\n",
    "            \"latents\" : Tensor[B x N*D x T]\n",
    "                Projected latents (continuous representation of input before quantization)\n",
    "            \"vq/commitment_loss\" : Tensor[1]\n",
    "                Commitment loss to train encoder to predict vectors closer to codebook\n",
    "                entries\n",
    "            \"vq/codebook_loss\" : Tensor[1]\n",
    "                Codebook loss to update the codebook\n",
    "        \"\"\"\n",
    "        z_q = 0\n",
    "        residual = z\n",
    "        commitment_loss = 0\n",
    "        codebook_loss = 0\n",
    "\n",
    "        codebook_indices = []\n",
    "        latents = []\n",
    "\n",
    "        if n_quantizers is None:\n",
    "            n_quantizers = self.n_codebooks\n",
    "        if self.training:\n",
    "            n_quantizers = torch.ones((z.shape[0],)) * self.n_codebooks + 1\n",
    "            dropout = torch.randint(1, self.n_codebooks + 1, (z.shape[0],))\n",
    "            n_dropout = int(z.shape[0] * self.quantizer_dropout)\n",
    "            n_quantizers[:n_dropout] = dropout[:n_dropout]\n",
    "            n_quantizers = n_quantizers.to(z.device)\n",
    "\n",
    "        for i, quantizer in enumerate(self.quantizers):\n",
    "            if self.training is False and i >= n_quantizers:\n",
    "                break\n",
    "\n",
    "            z_q_i, commitment_loss_i, codebook_loss_i, indices_i, z_e_i = quantizer(\n",
    "                residual\n",
    "            )\n",
    "\n",
    "            # Create mask to apply quantizer dropout\n",
    "            mask = (\n",
    "                torch.full((z.shape[0],), fill_value=i, device=z.device) < n_quantizers\n",
    "            )\n",
    "            z_q = z_q + z_q_i * mask[:, None, None]\n",
    "            residual = residual - z_q_i\n",
    "\n",
    "            # Sum losses\n",
    "            commitment_loss += (commitment_loss_i * mask).mean()\n",
    "            codebook_loss += (codebook_loss_i * mask).mean()\n",
    "\n",
    "            codebook_indices.append(indices_i)\n",
    "            latents.append(z_e_i)\n",
    "\n",
    "        codes = torch.stack(codebook_indices, dim=1)\n",
    "        latents = torch.cat(latents, dim=1)\n",
    "\n",
    "        return z_q, codes, latents, commitment_loss, codebook_loss\n",
    "\n",
    "    def from_codes(self, codes: torch.Tensor):\n",
    "        \"\"\"Given the quantized codes, reconstruct the continuous representation\n",
    "        Parameters\n",
    "        ----------\n",
    "        codes : Tensor[B x N x T]\n",
    "            Quantized discrete representation of input\n",
    "        Returns\n",
    "        -------\n",
    "        Tensor[B x D x T]\n",
    "            Quantized continuous representation of input\n",
    "        \"\"\"\n",
    "        z_q = 0.0\n",
    "        z_p = []\n",
    "        n_codebooks = codes.shape[1]\n",
    "        for i in range(n_codebooks):\n",
    "            z_p_i = self.quantizers[i].decode_code(codes[:, i, :])\n",
    "            z_p.append(z_p_i)\n",
    "\n",
    "            z_q_i = self.quantizers[i].out_proj(z_p_i)\n",
    "            z_q = z_q + z_q_i\n",
    "        return z_q, torch.cat(z_p, dim=1), codes\n",
    "\n",
    "    def from_latents(self, latents: torch.Tensor):\n",
    "        \"\"\"Given the unquantized latents, reconstruct the\n",
    "        continuous representation after quantization.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        latents : Tensor[B x N x T]\n",
    "            Continuous representation of input after projection\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tensor[B x D x T]\n",
    "            Quantized representation of full-projected space\n",
    "        Tensor[B x D x T]\n",
    "            Quantized representation of latent space\n",
    "        \"\"\"\n",
    "        z_q = 0\n",
    "        z_p = []\n",
    "        codes = []\n",
    "        dims = np.cumsum([0] + [q.codebook_dim for q in self.quantizers])\n",
    "\n",
    "        n_codebooks = np.where(dims <= latents.shape[1])[0].max(axis=0, keepdims=True)[\n",
    "            0\n",
    "        ]\n",
    "        for i in range(n_codebooks):\n",
    "            j, k = dims[i], dims[i + 1]\n",
    "            z_p_i, codes_i = self.quantizers[i].decode_latents(latents[:, j:k, :])\n",
    "            z_p.append(z_p_i)\n",
    "            codes.append(codes_i)\n",
    "\n",
    "            z_q_i = self.quantizers[i].out_proj(z_p_i)\n",
    "            z_q = z_q + z_q_i\n",
    "\n",
    "        return z_q, torch.cat(z_p, dim=1), torch.stack(codes, dim=1)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "rvq = ResidualVectorQuantize(1024, 2, 1024, 8)\n",
    "rvq.quantizers[0].in_proj.weight_v.data = torch.randn(8, 1024, 1)\n",
    "rvq.quantizers[0].in_proj.weight_g.data = torch.randn(8, 1, 1)\n",
    "rvq.quantizers[0].in_proj.bias.data = torch.randn(8)\n",
    "rvq.quantizers[0].out_proj.weight_v.data = torch.randn(1024, 8, 1)\n",
    "rvq.quantizers[0].out_proj.weight_g.data = torch.randn(1024, 1, 1)\n",
    "rvq.quantizers[0].out_proj.bias.data = torch.randn(1024)\n",
    "rvq.quantizers[0].codebook.weight.data = torch.randn(1024, 8)\n",
    "\n",
    "rvq.quantizers[1].in_proj.weight_v.data = torch.randn(8, 1024, 1)\n",
    "rvq.quantizers[1].in_proj.weight_g.data = torch.randn(8, 1, 1)\n",
    "rvq.quantizers[1].in_proj.bias.data = torch.randn(8)\n",
    "rvq.quantizers[1].out_proj.weight_v.data = torch.randn(1024, 8, 1)\n",
    "rvq.quantizers[1].out_proj.weight_g.data = torch.randn(1024, 1, 1)\n",
    "rvq.quantizers[1].out_proj.bias.data = torch.randn(1024)\n",
    "rvq.quantizers[1].codebook.weight.data = torch.randn(1024, 8)\n",
    "\n",
    "rvq_z_q, rvq_indices, _, _, _ = rvq(z)\n",
    "print(rvq_z_q, rvq_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import ir as I</span>\n",
       "<span style=\"color: #007979; font-style: italic\"># from tvm.script import relax as R</span>\n",
       "\n",
       "<span style=\"color: #AA22FF\">@I</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #0000FF; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">_initialize_effect</span>() <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tuple(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object):\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            _io: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>null_value()\n",
       "            lv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tuple(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object) <span style=\"color: #AA22FF; font-weight: bold\">=</span> (_io,)\n",
       "            gv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tuple(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object) <span style=\"color: #AA22FF; font-weight: bold\">=</span> lv\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">forward</span>(z: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">500</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), _io: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object, in_proj_weight_g: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), in_proj_weight_v: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), in_proj_bias: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">8</span>,), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), out_proj_weight_g: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), out_proj_weight_v: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), out_proj_bias: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>,), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), codebook_weight: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tuple(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tuple(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">500</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">500</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;int32&quot;</span>)), R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tuple(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object)):\n",
       "        R<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;num_input&quot;</span>: <span style=\"color: #008000\">2</span>})\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>square(in_proj_weight_v)\n",
       "            lv2: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>sum(lv1, axis<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">2</span>], keepdims<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "            lv3: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>sqrt(lv2)\n",
       "            lv4: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>divide(in_proj_weight_v, lv3)\n",
       "            wnconv1d: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>multiply(in_proj_weight_g, lv4)\n",
       "            lv5: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">500</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>nn<span style=\"color: #AA22FF; font-weight: bold\">.</span>conv1d(z, wnconv1d, strides<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>], padding<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">0</span>, <span style=\"color: #008000\">0</span>], dilation<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>], groups<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, data_layout<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCW&quot;</span>, kernel_layout<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;OIW&quot;</span>, out_layout<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCW&quot;</span>, out_dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;void&quot;</span>)\n",
       "            lv6: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>reshape(in_proj_bias, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>shape([<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1</span>]))\n",
       "            conv1d: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">500</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>add(lv5, lv6)\n",
       "            permute_dims: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">500</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>permute_dims(conv1d, axes<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">0</span>, <span style=\"color: #008000\">2</span>, <span style=\"color: #008000\">1</span>])\n",
       "            reshape: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>reshape(permute_dims, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>shape([<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">8</span>]))\n",
       "            square: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>square(reshape)\n",
       "            sum: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>sum(square, axis<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>], keepdims<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "            broadcast_to: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>broadcast_to(sum, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>shape([<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">8</span>]))\n",
       "            maximum: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>maximum(broadcast_to, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>const(<span style=\"color: #008000\">9.999999960041972e-13</span>, <span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            sqrt: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>sqrt(maximum)\n",
       "            divide: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>divide(reshape, sqrt)\n",
       "            square1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>square(codebook_weight)\n",
       "            sum1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>sum(square1, axis<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>], keepdims<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "            broadcast_to1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>broadcast_to(sum1, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>shape([<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">8</span>]))\n",
       "            maximum1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>maximum(broadcast_to1, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>const(<span style=\"color: #008000\">9.999999960041972e-13</span>, <span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            sqrt1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>sqrt(maximum1)\n",
       "            divide1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>divide(codebook_weight, sqrt1)\n",
       "            square2: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>square(divide)\n",
       "            sum2: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>sum(square2, axis<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>], keepdims<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "            permute_dims1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1024</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>permute_dims(divide1, axes<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">0</span>])\n",
       "            matmul: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">1024</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>matmul(divide, permute_dims1, out_dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;void&quot;</span>)\n",
       "            mul: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">1024</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>multiply(matmul, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>const(<span style=\"color: #008000\">2.0</span>, <span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            subtract: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">1024</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>subtract(sum2, mul)\n",
       "            square3: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>square(divide1)\n",
       "            sum3: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>sum(square3, axis<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>], keepdims<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "            permute_dims2: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1024</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>permute_dims(sum3, axes<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">0</span>])\n",
       "            add: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">1024</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>add(subtract, permute_dims2)\n",
       "            argsort: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">1024</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;int32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>argsort(add, axis<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, descending<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">False</span>, dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;int32&quot;</span>)\n",
       "            take: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;int32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>take(argsort, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">0</span>], axis<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>)\n",
       "            reshape1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">500</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;int32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>reshape(take, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>shape([<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">500</span>]))\n",
       "            reshape2: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>,), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;int32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>reshape(reshape1, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>shape([<span style=\"color: #008000\">16000</span>]))\n",
       "            take1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>take(codebook_weight, reshape2, axis<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">0</span>)\n",
       "            reshape3: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">500</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>reshape(take1, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>shape([<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">500</span>, <span style=\"color: #008000\">8</span>]))\n",
       "            permute_dims3: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">500</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>permute_dims(reshape3, axes<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">0</span>, <span style=\"color: #008000\">2</span>, <span style=\"color: #008000\">1</span>])\n",
       "            lv7: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>square(out_proj_weight_v)\n",
       "            lv8: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>sum(lv7, axis<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">2</span>], keepdims<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "            lv9: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>sqrt(lv8)\n",
       "            lv10: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>divide(out_proj_weight_v, lv9)\n",
       "            wnconv1d1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>multiply(out_proj_weight_g, lv10)\n",
       "            lv11: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">500</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>nn<span style=\"color: #AA22FF; font-weight: bold\">.</span>conv1d(permute_dims3, wnconv1d1, strides<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>], padding<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">0</span>, <span style=\"color: #008000\">0</span>], dilation<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>], groups<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, data_layout<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCW&quot;</span>, kernel_layout<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;OIW&quot;</span>, out_layout<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCW&quot;</span>, out_dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;void&quot;</span>)\n",
       "            lv12: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>reshape(out_proj_bias, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>shape([<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1</span>]))\n",
       "            conv1d1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">500</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>add(lv11, lv12)\n",
       "            gv1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tuple(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tuple(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">500</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">500</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;int32&quot;</span>)), R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tuple(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object)) <span style=\"color: #AA22FF; font-weight: bold\">=</span> (conv1d1, reshape1), (_io,)\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv1)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv1\n",
       "\n",
       "<span style=\"color: #007979; font-style: italic\"># Metadata omitted. Use show_meta=True in script() method to show it.</span>\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import Optional\n",
    "import tvm\n",
    "from tvm import relax\n",
    "from tvm.relax import op as _op\n",
    "from tvm.relax.frontend import nn\n",
    "from tvm import te\n",
    "from tvm import dlight as dl\n",
    "from tvm.target import Target\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def normalize(x: nn.Tensor, axis: Optional[int] = 1, eps: float = 1e-12):\n",
    "    denom = nn.op.sum(nn.op.square(x), axis=axis, keepdims=True)\n",
    "    denom = nn.op.sqrt(nn.op.maximum(nn.op.broadcast_to(denom, x.shape), nn.Tensor.from_const(eps)))\n",
    "    return x / denom\n",
    "\n",
    "\n",
    "class WNConv1d(nn.Module):\n",
    "    \"\"\"\n",
    "    Module for conv1d layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: int,\n",
    "        stride: int = 1,\n",
    "        padding: int = 0,\n",
    "        dilation: int = 1,\n",
    "        groups: int = 1,\n",
    "        bias: bool = True,\n",
    "        dtype: Optional[str] = None,\n",
    "    ) -> None:\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "        self.groups = groups\n",
    "        self.dtype = dtype\n",
    "\n",
    "        self.weight_g = nn.Parameter(\n",
    "            (\n",
    "                self.out_channels,\n",
    "                1,\n",
    "                1,\n",
    "            ),\n",
    "            dtype,\n",
    "        )\n",
    "\n",
    "        self.weight_v = nn.Parameter(\n",
    "            (\n",
    "                self.out_channels,\n",
    "                self.in_channels // self.groups,\n",
    "                self.kernel_size,\n",
    "            ),\n",
    "            dtype,\n",
    "        )\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter((self.out_channels,), dtype)\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "    def forward(self, x: nn.Tensor) -> nn.Tensor:\n",
    "        dim = [i for i in range(1, x.ndim)]\n",
    "        norm_v = _op.sqrt(\n",
    "            _op.sum(_op.square(self.weight_v._expr), axis=dim, keepdims=True),\n",
    "        )\n",
    "        weight = nn.wrap_nested(\n",
    "            self.weight_g._expr * (self.weight_v._expr / norm_v), name=\"wnconv1d\"\n",
    "        )\n",
    "        return nn.op.conv1d(\n",
    "            x, weight, self.bias, self.stride, self.padding, self.dilation, self.groups\n",
    "        )\n",
    "\n",
    "\n",
    "class VectorQuantize(nn.Module):\n",
    "    def __init__(self, input_dim: int, codebook_size: int, codebook_dim: int):\n",
    "        self.codebook_size = codebook_size\n",
    "        self.codebook_dim = codebook_dim\n",
    "\n",
    "        self.in_proj = WNConv1d(input_dim, codebook_dim, kernel_size=1)\n",
    "        self.out_proj = WNConv1d(codebook_dim, input_dim, kernel_size=1)\n",
    "        self.codebook = nn.Embedding(codebook_size, codebook_dim)\n",
    "\n",
    "    def forward(self, z: nn.Tensor):\n",
    "        z_e = self.in_proj(z)\n",
    "        z_q, indices = self.decode_latents(z_e)\n",
    "        z_q = self.out_proj(z_q)\n",
    "        return z_q, indices\n",
    "\n",
    "    def decode_latents(self, latents: nn.Tensor):    \n",
    "        encodings = nn.op.permute_dims(latents, [0, 2, 1])  # (b, t, d)\n",
    "        encodings = nn.op.reshape(encodings, [-1, encodings.shape[2]])  # (b*t, d)\n",
    "        codebook = self.codebook.weight\n",
    "\n",
    "        encodings = normalize(encodings)  # (b*t, d)\n",
    "        codebook = normalize(codebook)  # (N, d)\n",
    "\n",
    "        dist = (\n",
    "            nn.op.sum(nn.op.square(encodings), axis=1, keepdims=True)  # (b*t, 1)\n",
    "            - 2\n",
    "            * nn.op.matmul(encodings, nn.op.permute_dims(codebook, [1, 0]))  # (b*t, N)\n",
    "            + nn.op.permute_dims(\n",
    "                nn.op.sum(nn.op.square(codebook), axis=1, keepdims=True), [1, 0]\n",
    "            )  # (1, N)\n",
    "        )  # (b*t, N)\n",
    "\n",
    "        indices = nn.op.argsort(dist, axis=1)  # (b*t, N)\n",
    "        indices = nn.op.take(indices, nn.Tensor.from_const([0]), axis=1)  # (b*t, 1)\n",
    "        indices = nn.op.reshape(indices, [latents.shape[0], latents.shape[2]])  # (b, t)\n",
    "\n",
    "        z_q = self.codebook(indices) # (b, t, d)\n",
    "        z_q = nn.op.permute_dims(z_q, [0, 2, 1]) # (b, d, t)\n",
    "        return z_q, indices\n",
    "\n",
    "\n",
    "mod, params = VectorQuantize(1024, 1024, 8).export_tvm(\n",
    "    {\"forward\": {\"z\": nn.spec.Tensor((32, 1024, 500), \"float32\")}}, debug=True\n",
    ")\n",
    "mod.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metal -keys=metal,gpu -max_function_args=31 -max_num_threads=256 -max_shared_memory_per_block=32768 -max_threads_per_block=1024 -thread_warp_size=32\n",
      "Elapsed time:  0.0020580291748046875\n",
      "[[[ 0.9988062   0.9286075   0.8645287  ...  0.8869156   0.79730624\n",
      "    0.8903235 ]\n",
      "  [-0.17046398 -0.7351244   0.47651774 ... -0.10897435 -0.10779934\n",
      "    0.03020364]\n",
      "  [-0.42893085 -1.6530032  -0.5824416  ... -0.97907007 -0.45231423\n",
      "   -0.6140453 ]\n",
      "  ...\n",
      "  [-3.6224961  -1.5332791  -2.9127078  ... -1.9451369  -3.50908\n",
      "   -1.4742826 ]\n",
      "  [ 0.42801517  0.5834759   0.65450764 ...  0.59538335  0.43885562\n",
      "    0.80032337]\n",
      "  [-1.1395632  -1.8114793  -0.7024274  ... -1.7644299  -1.3500917\n",
      "   -0.7024373 ]]\n",
      "\n",
      " [[ 0.9899451   0.7914734   0.8645287  ...  0.96066576  0.85459185\n",
      "    0.9807827 ]\n",
      "  [-0.87882215 -0.07316126  0.47651774 ... -0.20981178 -1.0006511\n",
      "    0.09284002]\n",
      "  [-0.5385559  -0.64032966 -0.5824416  ... -1.4164237  -1.976311\n",
      "   -0.44821826]\n",
      "  ...\n",
      "  [-3.064777   -2.413759   -2.9127078  ... -3.3440204  -3.2999063\n",
      "   -3.043821  ]\n",
      "  [ 0.19349998  0.426827    0.65450764 ...  0.623234    0.80561095\n",
      "    0.6058308 ]\n",
      "  [-1.5807371  -1.2421002  -0.7024274  ... -2.1177175  -1.9799663\n",
      "   -1.4128364 ]]\n",
      "\n",
      " [[ 0.8903235   0.9075106   0.85459185 ...  0.8645287   0.8645287\n",
      "    0.8450963 ]\n",
      "  [ 0.03020364 -0.52619064 -1.0006511  ...  0.47651774  0.47651774\n",
      "   -0.48228452]\n",
      "  [-0.6140453  -1.0764482  -1.976311   ... -0.5824416  -0.5824416\n",
      "   -1.5488716 ]\n",
      "  ...\n",
      "  [-1.4742826  -1.0178778  -3.2999063  ... -2.9127078  -2.9127078\n",
      "   -3.049481  ]\n",
      "  [ 0.80032337  0.53080255  0.80561095 ...  0.65450764  0.65450764\n",
      "    0.51456016]\n",
      "  [-0.7024373  -1.2589359  -1.9799663  ... -0.7024274  -0.7024274\n",
      "   -1.6265953 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1.0319096   0.8645287   0.8903235  ...  0.8903235   0.835538\n",
      "    0.9075106 ]\n",
      "  [-0.24667019  0.47651774  0.03020364 ...  0.03020364  0.43901145\n",
      "   -0.52619064]\n",
      "  [-1.1517743  -0.5824416  -0.6140453  ... -0.6140453   0.2521786\n",
      "   -1.0764482 ]\n",
      "  ...\n",
      "  [-2.9844515  -2.9127078  -1.4742826  ... -1.4742826  -3.5104942\n",
      "   -1.0178778 ]\n",
      "  [ 0.41236764  0.65450764  0.80032337 ...  0.80032337  0.45911852\n",
      "    0.53080255]\n",
      "  [-1.7411938  -0.7024274  -0.7024373  ... -0.7024373  -0.6513921\n",
      "   -1.2589359 ]]\n",
      "\n",
      " [[ 0.9286075   0.8629519   0.85459185 ...  0.8903235   0.9075106\n",
      "    0.8645287 ]\n",
      "  [-0.7351244  -0.61115396 -1.0006511  ...  0.03020364 -0.52619064\n",
      "    0.47651774]\n",
      "  [-1.6530032  -1.1570352  -1.976311   ... -0.6140453  -1.0764482\n",
      "   -0.5824416 ]\n",
      "  ...\n",
      "  [-1.5332791  -0.92667836 -3.2999063  ... -1.4742826  -1.0178778\n",
      "   -2.9127078 ]\n",
      "  [ 0.5834759   0.4052387   0.80561095 ...  0.80032337  0.53080255\n",
      "    0.65450764]\n",
      "  [-1.8114793  -2.120785   -1.9799663  ... -0.7024373  -1.2589359\n",
      "   -0.7024274 ]]\n",
      "\n",
      " [[ 0.79730624  0.8962549   0.8645287  ...  0.79730624  0.96335745\n",
      "    0.8914609 ]\n",
      "  [-0.10779934 -0.41596445  0.47651774 ... -0.10779934  0.18531685\n",
      "   -0.4764579 ]\n",
      "  [-0.45231423 -1.1876214  -0.5824416  ... -0.45231423 -1.5675075\n",
      "   -1.6541679 ]\n",
      "  ...\n",
      "  [-3.50908    -3.8934546  -2.9127078  ... -3.50908    -1.8993448\n",
      "   -3.9653182 ]\n",
      "  [ 0.43885562  0.8837625   0.65450764 ...  0.43885562  0.61197937\n",
      "    0.4624282 ]\n",
      "  [-1.3500917  -1.829435   -0.7024274  ... -1.3500917  -1.8466792\n",
      "   -2.1275945 ]]]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "target = Target.from_device(\"metal\")\n",
    "print(target)\n",
    "with target:\n",
    "    mod = relax.transform.LegalizeOps()(mod)\n",
    "    mod = dl.ApplyDefaultSchedule(\n",
    "        # dl.gpu.Matmul(),\n",
    "        dl.gpu.GEMV(),\n",
    "        dl.gpu.Reduction(),\n",
    "        dl.gpu.GeneralReduction(),\n",
    "        dl.gpu.Fallback(),\n",
    "    )(mod)\n",
    "ex = relax.build(mod, target)\n",
    "device = tvm.metal()\n",
    "\n",
    "vm = relax.VirtualMachine(ex, device)\n",
    "tvm_data = tvm.nd.array(z, device=device)\n",
    "# print(params)\n",
    "\n",
    "tvm_params = [\n",
    "    vq.in_proj.weight_g.data.numpy().astype(\"float32\"),\n",
    "    vq.in_proj.weight_v.data.numpy().astype(\"float32\"),\n",
    "    vq.in_proj.bias.data.numpy().astype(\"float32\"),\n",
    "    vq.out_proj.weight_g.data.numpy().astype(\"float32\"),\n",
    "    vq.out_proj.weight_v.data.numpy().astype(\"float32\"),\n",
    "    vq.out_proj.bias.data.numpy().astype(\"float32\"),\n",
    "    vq.codebook.weight.data.numpy().astype(\"float32\"),\n",
    "]\n",
    "tvm_params = [tvm.nd.array(param, device=device) for param in tvm_params]\n",
    "# print(tvm_params)\n",
    "\n",
    "start = time.time()\n",
    "effects = vm[\"_initialize_effect\"]()\n",
    "z_q_tvm, indices_tvm = vm[\"forward\"](tvm_data, *effects, *tvm_params)[0]\n",
    "print(\"Elapsed time: \", time.time() - start)\n",
    "\n",
    "print(z_q_tvm.numpy())\n",
    "assert np.allclose(z_q.detach().numpy(), z_q_tvm.numpy(), atol=1e-3)\n",
    "assert np.allclose(indices.detach().numpy(), indices_tvm.numpy(), atol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import ir as I</span>\n",
       "<span style=\"color: #007979; font-style: italic\"># from tvm.script import relax as R</span>\n",
       "\n",
       "<span style=\"color: #AA22FF\">@I</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #0000FF; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">_initialize_effect</span>() <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tuple(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object):\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            _io: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>null_value()\n",
       "            lv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tuple(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object) <span style=\"color: #AA22FF; font-weight: bold\">=</span> (_io,)\n",
       "            gv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tuple(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object) <span style=\"color: #AA22FF; font-weight: bold\">=</span> lv\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">forward</span>(z: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">500</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), _io: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object, quantizers_0_in_proj_weight_g: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), quantizers_0_in_proj_weight_v: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), quantizers_0_in_proj_bias: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">8</span>,), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), quantizers_0_out_proj_weight_g: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), quantizers_0_out_proj_weight_v: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), quantizers_0_out_proj_bias: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>,), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), quantizers_0_codebook_weight: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), quantizers_1_in_proj_weight_g: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), quantizers_1_in_proj_weight_v: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), quantizers_1_in_proj_bias: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">8</span>,), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), quantizers_1_out_proj_weight_g: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), quantizers_1_out_proj_weight_v: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), quantizers_1_out_proj_bias: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>,), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), quantizers_1_codebook_weight: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tuple(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tuple(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">500</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tuple(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">500</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;int32&quot;</span>), R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">500</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;int32&quot;</span>))), R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tuple(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object)):\n",
       "        R<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;num_input&quot;</span>: <span style=\"color: #008000\">2</span>})\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            zeros: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">500</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>zeros(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>shape([<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">500</span>]), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            lv1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>square(quantizers_0_in_proj_weight_v)\n",
       "            lv2: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>sum(lv1, axis<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">2</span>], keepdims<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "            lv3: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>sqrt(lv2)\n",
       "            lv4: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>divide(quantizers_0_in_proj_weight_v, lv3)\n",
       "            wnconv1d: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>multiply(quantizers_0_in_proj_weight_g, lv4)\n",
       "            lv5: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">500</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>nn<span style=\"color: #AA22FF; font-weight: bold\">.</span>conv1d(z, wnconv1d, strides<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>], padding<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">0</span>, <span style=\"color: #008000\">0</span>], dilation<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>], groups<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, data_layout<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCW&quot;</span>, kernel_layout<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;OIW&quot;</span>, out_layout<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCW&quot;</span>, out_dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;void&quot;</span>)\n",
       "            lv6: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>reshape(quantizers_0_in_proj_bias, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>shape([<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1</span>]))\n",
       "            conv1d: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">500</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>add(lv5, lv6)\n",
       "            permute_dims: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">500</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>permute_dims(conv1d, axes<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">0</span>, <span style=\"color: #008000\">2</span>, <span style=\"color: #008000\">1</span>])\n",
       "            reshape: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>reshape(permute_dims, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>shape([<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">8</span>]))\n",
       "            square: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>square(reshape)\n",
       "            sum: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>sum(square, axis<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>], keepdims<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "            broadcast_to: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>broadcast_to(sum, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>shape([<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">8</span>]))\n",
       "            maximum: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>maximum(broadcast_to, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>const(<span style=\"color: #008000\">9.999999960041972e-13</span>, <span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            sqrt: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>sqrt(maximum)\n",
       "            divide: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>divide(reshape, sqrt)\n",
       "            square1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>square(quantizers_0_codebook_weight)\n",
       "            sum1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>sum(square1, axis<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>], keepdims<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "            broadcast_to1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>broadcast_to(sum1, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>shape([<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">8</span>]))\n",
       "            maximum1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>maximum(broadcast_to1, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>const(<span style=\"color: #008000\">9.999999960041972e-13</span>, <span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            sqrt1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>sqrt(maximum1)\n",
       "            divide1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>divide(quantizers_0_codebook_weight, sqrt1)\n",
       "            square2: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>square(divide)\n",
       "            sum2: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>sum(square2, axis<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>], keepdims<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "            permute_dims1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1024</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>permute_dims(divide1, axes<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">0</span>])\n",
       "            matmul: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">1024</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>matmul(divide, permute_dims1, out_dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;void&quot;</span>)\n",
       "            mul: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">1024</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>multiply(matmul, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>const(<span style=\"color: #008000\">2.0</span>, <span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            subtract: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">1024</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>subtract(sum2, mul)\n",
       "            square3: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>square(divide1)\n",
       "            sum3: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>sum(square3, axis<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>], keepdims<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "            permute_dims2: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1024</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>permute_dims(sum3, axes<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">0</span>])\n",
       "            add: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">1024</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>add(subtract, permute_dims2)\n",
       "            argsort: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">1024</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;int32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>argsort(add, axis<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, descending<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">False</span>, dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;int32&quot;</span>)\n",
       "            take: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;int32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>take(argsort, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">0</span>], axis<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>)\n",
       "            reshape1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">500</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;int32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>reshape(take, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>shape([<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">500</span>]))\n",
       "            reshape2: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>,), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;int32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>reshape(reshape1, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>shape([<span style=\"color: #008000\">16000</span>]))\n",
       "            take1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>take(quantizers_0_codebook_weight, reshape2, axis<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">0</span>)\n",
       "            reshape3: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">500</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>reshape(take1, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>shape([<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">500</span>, <span style=\"color: #008000\">8</span>]))\n",
       "            permute_dims3: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">500</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>permute_dims(reshape3, axes<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">0</span>, <span style=\"color: #008000\">2</span>, <span style=\"color: #008000\">1</span>])\n",
       "            lv7: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>square(quantizers_0_out_proj_weight_v)\n",
       "            lv8: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>sum(lv7, axis<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">2</span>], keepdims<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "            lv9: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>sqrt(lv8)\n",
       "            lv10: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>divide(quantizers_0_out_proj_weight_v, lv9)\n",
       "            wnconv1d1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>multiply(quantizers_0_out_proj_weight_g, lv10)\n",
       "            lv11: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">500</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>nn<span style=\"color: #AA22FF; font-weight: bold\">.</span>conv1d(permute_dims3, wnconv1d1, strides<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>], padding<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">0</span>, <span style=\"color: #008000\">0</span>], dilation<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>], groups<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, data_layout<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCW&quot;</span>, kernel_layout<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;OIW&quot;</span>, out_layout<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCW&quot;</span>, out_dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;void&quot;</span>)\n",
       "            lv12: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>reshape(quantizers_0_out_proj_bias, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>shape([<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1</span>]))\n",
       "            conv1d1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">500</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>add(lv11, lv12)\n",
       "            add1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">500</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>add(zeros, conv1d1)\n",
       "            subtract1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">500</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>subtract(z, conv1d1)\n",
       "            lv13: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>square(quantizers_1_in_proj_weight_v)\n",
       "            lv14: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>sum(lv13, axis<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">2</span>], keepdims<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "            lv15: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>sqrt(lv14)\n",
       "            lv16: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>divide(quantizers_1_in_proj_weight_v, lv15)\n",
       "            wnconv1d2: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>multiply(quantizers_1_in_proj_weight_g, lv16)\n",
       "            lv17: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">500</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>nn<span style=\"color: #AA22FF; font-weight: bold\">.</span>conv1d(subtract1, wnconv1d2, strides<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>], padding<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">0</span>, <span style=\"color: #008000\">0</span>], dilation<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>], groups<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, data_layout<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCW&quot;</span>, kernel_layout<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;OIW&quot;</span>, out_layout<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCW&quot;</span>, out_dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;void&quot;</span>)\n",
       "            lv18: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>reshape(quantizers_1_in_proj_bias, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>shape([<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1</span>]))\n",
       "            conv1d2: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">500</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>add(lv17, lv18)\n",
       "            permute_dims4: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">500</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>permute_dims(conv1d2, axes<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">0</span>, <span style=\"color: #008000\">2</span>, <span style=\"color: #008000\">1</span>])\n",
       "            reshape4: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>reshape(permute_dims4, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>shape([<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">8</span>]))\n",
       "            square4: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>square(reshape4)\n",
       "            sum4: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>sum(square4, axis<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>], keepdims<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "            broadcast_to2: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>broadcast_to(sum4, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>shape([<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">8</span>]))\n",
       "            maximum2: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>maximum(broadcast_to2, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>const(<span style=\"color: #008000\">9.999999960041972e-13</span>, <span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            sqrt2: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>sqrt(maximum2)\n",
       "            divide2: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>divide(reshape4, sqrt2)\n",
       "            square5: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>square(quantizers_1_codebook_weight)\n",
       "            sum5: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>sum(square5, axis<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>], keepdims<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "            broadcast_to3: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>broadcast_to(sum5, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>shape([<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">8</span>]))\n",
       "            maximum3: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>maximum(broadcast_to3, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>const(<span style=\"color: #008000\">9.999999960041972e-13</span>, <span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            sqrt3: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>sqrt(maximum3)\n",
       "            divide3: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>divide(quantizers_1_codebook_weight, sqrt3)\n",
       "            square6: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>square(divide2)\n",
       "            sum6: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>sum(square6, axis<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>], keepdims<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "            permute_dims5: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1024</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>permute_dims(divide3, axes<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">0</span>])\n",
       "            matmul1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">1024</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>matmul(divide2, permute_dims5, out_dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;void&quot;</span>)\n",
       "            mul1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">1024</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>multiply(matmul1, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>const(<span style=\"color: #008000\">2.0</span>, <span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            subtract2: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">1024</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>subtract(sum6, mul1)\n",
       "            square7: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>square(divide3)\n",
       "            sum7: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>sum(square7, axis<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>], keepdims<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "            permute_dims6: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1024</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>permute_dims(sum7, axes<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">0</span>])\n",
       "            add2: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">1024</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>add(subtract2, permute_dims6)\n",
       "            argsort1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">1024</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;int32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>argsort(add2, axis<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, descending<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">False</span>, dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;int32&quot;</span>)\n",
       "            take2: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;int32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>take(argsort1, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">1</span>], axis<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>)\n",
       "            reshape5: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">500</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;int32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>reshape(take2, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>shape([<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">500</span>]))\n",
       "            reshape6: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>,), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;int32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>reshape(reshape5, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>shape([<span style=\"color: #008000\">16000</span>]))\n",
       "            take3: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16000</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>take(quantizers_1_codebook_weight, reshape6, axis<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">0</span>)\n",
       "            reshape7: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">500</span>, <span style=\"color: #008000\">8</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>reshape(take3, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>shape([<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">500</span>, <span style=\"color: #008000\">8</span>]))\n",
       "            permute_dims7: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">500</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>permute_dims(reshape7, axes<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">0</span>, <span style=\"color: #008000\">2</span>, <span style=\"color: #008000\">1</span>])\n",
       "            lv19: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>square(quantizers_1_out_proj_weight_v)\n",
       "            lv20: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>sum(lv19, axis<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">2</span>], keepdims<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "            lv21: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>sqrt(lv20)\n",
       "            lv22: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>divide(quantizers_1_out_proj_weight_v, lv21)\n",
       "            wnconv1d3: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>multiply(quantizers_1_out_proj_weight_g, lv22)\n",
       "            lv23: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">500</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>nn<span style=\"color: #AA22FF; font-weight: bold\">.</span>conv1d(permute_dims7, wnconv1d3, strides<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>], padding<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">0</span>, <span style=\"color: #008000\">0</span>], dilation<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>], groups<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, data_layout<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCW&quot;</span>, kernel_layout<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;OIW&quot;</span>, out_layout<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCW&quot;</span>, out_dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;void&quot;</span>)\n",
       "            lv24: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>reshape(quantizers_1_out_proj_bias, R<span style=\"color: #AA22FF; font-weight: bold\">.</span>shape([<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1</span>]))\n",
       "            conv1d3: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">500</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>add(lv23, lv24)\n",
       "            add3: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">500</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>add(add1, conv1d3)\n",
       "            subtract3: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">500</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>subtract(subtract1, conv1d3)\n",
       "            gv1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tuple(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tuple(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">500</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tuple(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">500</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;int32&quot;</span>), R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">500</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;int32&quot;</span>))), R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tuple(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Object)) <span style=\"color: #AA22FF; font-weight: bold\">=</span> (add3, (reshape1, reshape5)), (_io,)\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv1)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv1\n",
       "\n",
       "<span style=\"color: #007979; font-style: italic\"># Metadata omitted. Use show_meta=True in script() method to show it.</span>\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class ResidualVectorQuantize(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int = 512,\n",
    "        n_codebooks: int = 9,\n",
    "        codebook_size: int = 1024,\n",
    "        codebook_dim: Union[int, list] = 8,\n",
    "        quantizer_dropout: float = 0.0,\n",
    "    ):\n",
    "        if isinstance(codebook_dim, int):\n",
    "            codebook_dim = [codebook_dim for _ in range(n_codebooks)]\n",
    "\n",
    "        self.n_codebooks = n_codebooks\n",
    "        self.codebook_dim = codebook_dim\n",
    "        self.codebook_size = codebook_size\n",
    "\n",
    "        self.quantizers = nn.ModuleList(\n",
    "            [\n",
    "                VectorQuantize(input_dim, codebook_size, codebook_dim[i])\n",
    "                for i in range(n_codebooks)\n",
    "            ]\n",
    "        )\n",
    "        self.quantizer_dropout = quantizer_dropout\n",
    "\n",
    "    def forward(self, z: nn.Tensor):\n",
    "        z_q = nn.zeros(z.shape, dtype=z.dtype)\n",
    "        residual = z\n",
    "        codebook_indices = []\n",
    "\n",
    "        for quantizer in self.quantizers:\n",
    "            z_q_i, indices = quantizer(residual)\n",
    "            z_q = z_q + z_q_i\n",
    "            residual = residual - z_q_i\n",
    "            codebook_indices.append(indices)\n",
    "        \n",
    "        return z_q, codebook_indices\n",
    "\n",
    "mod, params = ResidualVectorQuantize(1024, 2, 1024, 8).export_tvm(\n",
    "    {\"forward\": {\"z\": nn.spec.Tensor((32, 1024, 500), \"float32\")}}, debug=True\n",
    ")\n",
    "mod.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metal -keys=metal,gpu -max_function_args=31 -max_num_threads=256 -max_shared_memory_per_block=32768 -max_threads_per_block=1024 -thread_warp_size=32\n",
      "[('quantizers.0.in_proj.weight_g', Tensor([8, 1, 1], \"float32\")), ('quantizers.0.in_proj.weight_v', Tensor([8, 1024, 1], \"float32\")), ('quantizers.0.in_proj.bias', Tensor([8], \"float32\")), ('quantizers.0.out_proj.weight_g', Tensor([1024, 1, 1], \"float32\")), ('quantizers.0.out_proj.weight_v', Tensor([1024, 8, 1], \"float32\")), ('quantizers.0.out_proj.bias', Tensor([1024], \"float32\")), ('quantizers.0.codebook.weight', Tensor([1024, 8], \"float32\")), ('quantizers.1.in_proj.weight_g', Tensor([8, 1, 1], \"float32\")), ('quantizers.1.in_proj.weight_v', Tensor([8, 1024, 1], \"float32\")), ('quantizers.1.in_proj.bias', Tensor([8], \"float32\")), ('quantizers.1.out_proj.weight_g', Tensor([1024, 1, 1], \"float32\")), ('quantizers.1.out_proj.weight_v', Tensor([1024, 8, 1], \"float32\")), ('quantizers.1.out_proj.bias', Tensor([1024], \"float32\")), ('quantizers.1.codebook.weight', Tensor([1024, 8], \"float32\"))]\n",
      "torch.Size([32, 2, 500]) (32, 2, 500)\n",
      "Elapsed time:  0.06484389305114746\n",
      "[[[-3.8284192  -3.735267   -3.2694325  ... -4.2949696  -3.4027078\n",
      "   -4.8892603 ]\n",
      "  [-0.50322896 -3.1675978  -1.6385314  ... -2.0904176  -2.8226547\n",
      "   -0.13860679]\n",
      "  [ 0.57860476 -0.24358678 -0.49374044 ...  1.3624451   1.1955483\n",
      "   -0.214998  ]\n",
      "  ...\n",
      "  [-2.7137754  -2.9814072  -3.2481837  ... -2.6788964  -2.8203077\n",
      "   -2.757193  ]\n",
      "  [-0.40850857 -0.2235713  -0.16953486 ... -1.7219888  -0.48038054\n",
      "   -0.7997124 ]\n",
      "  [ 0.29233712 -0.11187103  0.02312861 ...  1.4828951   1.1780026\n",
      "    0.36396644]]\n",
      "\n",
      " [[-1.7458174  -4.6100526  -2.935422   ... -1.5002208  -5.484827\n",
      "   -2.708602  ]\n",
      "  [-0.8325978  -0.83299243 -0.90820396 ... -0.7709002  -2.2841058\n",
      "   -0.49772227]\n",
      "  [ 3.075937    0.15741807  0.95283645 ...  1.3161912   0.3701924\n",
      "    1.2299122 ]\n",
      "  ...\n",
      "  [-2.7903385  -3.0200052  -2.993269   ... -2.3978672  -2.5884917\n",
      "   -2.9738166 ]\n",
      "  [-0.3413148  -0.14082134 -0.06830013 ...  0.76508284 -0.9241295\n",
      "   -0.06086999]\n",
      "  [ 0.11404294 -0.34900504  0.17871036 ...  0.04822442  0.89805216\n",
      "   -0.13727215]]\n",
      "\n",
      " [[-3.45632    -3.7545013  -5.598775   ... -6.0925107  -4.1386724\n",
      "   -3.4019723 ]\n",
      "  [-2.0591102  -2.2037344  -2.6102903  ... -0.5444914  -1.3140886\n",
      "   -2.4953926 ]\n",
      "  [-1.2233008   2.1198828   0.18886721 ...  1.1288955   2.29673\n",
      "    1.7366767 ]\n",
      "  ...\n",
      "  [-3.110426   -2.9283636  -2.965764   ... -2.5406134  -2.776689\n",
      "   -2.9583898 ]\n",
      "  [-0.62570566 -1.3208373  -0.97307175 ... -1.1532519  -0.42183965\n",
      "   -1.3817804 ]\n",
      "  [ 0.49817318  1.1430057   0.6208347  ...  0.887473    0.7022169\n",
      "    1.3692683 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-3.7348337  -3.2621818  -3.155485   ... -3.2694325  -4.3813224\n",
      "   -4.201384  ]\n",
      "  [-1.4311706  -1.6274774  -1.3123469  ... -1.6385314  -2.3614693\n",
      "   -3.0183592 ]\n",
      "  [-0.206285    1.6832275  -0.31241524 ... -0.49374044 -0.11904705\n",
      "    0.5775553 ]\n",
      "  ...\n",
      "  [-2.8603373  -2.4792075  -2.8709111  ... -3.2481837  -2.925878\n",
      "   -2.825458  ]\n",
      "  [-0.06707972 -0.19690806 -0.12059259 ... -0.16953486  0.28446877\n",
      "   -1.3805599 ]\n",
      "  [ 0.39006603 -0.41327995  0.30034608 ...  0.02312861 -0.09116843\n",
      "    1.580624  ]]\n",
      "\n",
      " [[-4.201384   -5.0316696  -5.484827   ... -4.2674108  -3.8284192\n",
      "   -2.8995628 ]\n",
      "  [-3.0183592  -0.9091136  -2.2841058  ...  0.46345758 -0.50322896\n",
      "   -1.1005557 ]\n",
      "  [ 0.5775553   1.9224982   0.3701924  ... -0.03672528  0.57860476\n",
      "    2.2126193 ]\n",
      "  ...\n",
      "  [-2.825458   -2.4971957  -2.5884917  ... -3.1722505  -2.7137754\n",
      "   -2.5590668 ]\n",
      "  [-1.3805599  -0.7620481  -0.9241295  ... -1.1818514  -0.40850857\n",
      "   -0.42734575]\n",
      "  [ 1.580624    0.8158437   0.89805216 ...  0.34405735  0.29233712\n",
      "    1.0512643 ]]\n",
      "\n",
      " [[-3.7073429  -3.5389018  -2.307084   ... -3.7348337  -3.155485\n",
      "   -3.1731634 ]\n",
      "  [-0.9235855  -2.9374862  -1.5547255  ... -1.4311706  -1.3123469\n",
      "   -0.3476634 ]\n",
      "  [ 0.65098476  0.33134615  0.05621898 ... -0.206285   -0.31241524\n",
      "    1.8324789 ]\n",
      "  ...\n",
      "  [-2.5103765  -2.869735   -2.9083586  ... -2.8603373  -2.8709111\n",
      "   -2.8087888 ]\n",
      "  [-1.0492147  -1.2589309  -0.7553015  ... -0.06707972 -0.12059259\n",
      "    0.5250633 ]\n",
      "  [ 1.6012067   1.7430717   0.5545867  ...  0.39006603  0.30034608\n",
      "   -0.7498374 ]]]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "target = Target.from_device(\"metal\")\n",
    "print(target)\n",
    "with target:\n",
    "    mod = relax.transform.LegalizeOps()(mod)\n",
    "    mod = dl.ApplyDefaultSchedule(\n",
    "        # dl.gpu.Matmul(),\n",
    "        dl.gpu.GEMV(),\n",
    "        dl.gpu.Reduction(),\n",
    "        dl.gpu.GeneralReduction(),\n",
    "        dl.gpu.Fallback(),\n",
    "    )(mod)\n",
    "ex = relax.build(mod, target)\n",
    "device = tvm.metal()\n",
    "\n",
    "vm = relax.VirtualMachine(ex, device)\n",
    "tvm_data = tvm.nd.array(z, device=device)\n",
    "print(params)\n",
    "\n",
    "tvm_params = [\n",
    "    rvq.quantizers[0].in_proj.weight_g.data.numpy().astype(\"float32\"),\n",
    "    rvq.quantizers[0].in_proj.weight_v.data.numpy().astype(\"float32\"),\n",
    "    rvq.quantizers[0].in_proj.bias.data.numpy().astype(\"float32\"),\n",
    "    rvq.quantizers[0].out_proj.weight_g.data.numpy().astype(\"float32\"),\n",
    "    rvq.quantizers[0].out_proj.weight_v.data.numpy().astype(\"float32\"),\n",
    "    rvq.quantizers[0].out_proj.bias.data.numpy().astype(\"float32\"),\n",
    "    rvq.quantizers[0].codebook.weight.data.numpy().astype(\"float32\"),\n",
    "    rvq.quantizers[1].in_proj.weight_g.data.numpy().astype(\"float32\"),\n",
    "    rvq.quantizers[1].in_proj.weight_v.data.numpy().astype(\"float32\"),\n",
    "    rvq.quantizers[1].in_proj.bias.data.numpy().astype(\"float32\"),\n",
    "    rvq.quantizers[1].out_proj.weight_g.data.numpy().astype(\"float32\"),\n",
    "    rvq.quantizers[1].out_proj.weight_v.data.numpy().astype(\"float32\"),\n",
    "    rvq.quantizers[1].out_proj.bias.data.numpy().astype(\"float32\"),\n",
    "    rvq.quantizers[1].codebook.weight.data.numpy().astype(\"float32\"),\n",
    "]\n",
    "tvm_params = [tvm.nd.array(param, device=device) for param in tvm_params]\n",
    "# print(tvm_params)\n",
    "\n",
    "start = time.time()\n",
    "effects = vm[\"_initialize_effect\"]()\n",
    "rvq_z_q_tvm, rvq_indices_tvm = vm[\"forward\"](tvm_data, *effects, *tvm_params)[0]\n",
    "rvq_indices_tvm = map(lambda x: x.numpy(), rvq_indices_tvm)\n",
    "rvq_indices_tvm = np.stack(list(rvq_indices_tvm), axis=1)\n",
    "print(rvq_indices.shape, rvq_indices_tvm.shape)\n",
    "print(\"Elapsed time: \", time.time() - start)\n",
    "\n",
    "print(rvq_z_q_tvm.numpy())\n",
    "assert np.allclose(rvq_z_q.detach().numpy(), rvq_z_q_tvm.numpy(), atol=1e-3)\n",
    "assert np.allclose(rvq_indices.detach().numpy(), rvq_indices_tvm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlc-audio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
